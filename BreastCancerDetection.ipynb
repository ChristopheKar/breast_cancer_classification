{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BreastCancerDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wpUFHwaFzBHF",
        "3C2CzK7woe_t",
        "r86wyigbovjv",
        "dLlbj3F8oyMz",
        "iU0IOYXVo0L_",
        "v-nDK8HBo1Lb",
        "q9k_Rx7zo2Gd"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUGqex8hr-D2",
        "colab_type": "text"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqhA5DYtxBFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvwwkx6-dXZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install pydicom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2UtxU1VHZ0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive to Session\n",
        "import os\n",
        "from google.colab import drive\n",
        "if not os.path.isdir('drive'):\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltBxfkEqKmM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load standard modules\n",
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Load data modules\n",
        "import pandas as pd\n",
        "# import pydicom as dicom\n",
        "import numpy as np\n",
        "\n",
        "# Load image and plotting modules\n",
        "import cv2\n",
        "import plistlib\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.draw import polygon\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v33RSQIDgNHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!unzip /content/drive/'My Drive'/'Breast Cancer Detection'/breast_cancer_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw65MQ06JAfx",
        "colab_type": "text"
      },
      "source": [
        "## Importing and Processing Datasets for Breast Cancer Detection\n",
        "\n",
        "Datasets involved are: \n",
        "\n",
        "1.   **MIAS**: 322 images for 161 cases, labels for malignant, benign, and normal cases, additionnal bounding-circle annotations for abnormalities.\n",
        "2.   **INbreast:** 410 images for 115 cases (90 cases * 4 images + 25 cases * 2 images)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-qScPD8L6i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dir(dir_path, verbose=True):\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "        if verbose:\n",
        "            print(f'Created directory at {dir_path}.')\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f'Directory exists at {dir_path}.')\n",
        "\n",
        "\n",
        "def download(url, fname):\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        chunk_count = 1\n",
        "        chunk_size = 1024\n",
        "        total_length = int(r.headers.get('content-length'))\n",
        "        for chunk in r.iter_content(chunk_size=chunk_size): \n",
        "            if chunk:\n",
        "                print(f'Downloading file: {chunk_count*chunk_size}/{total_length}', end='\\r')\n",
        "                f.write(chunk)\n",
        "                f.flush()\n",
        "                chunk_count += 1\n",
        "        print(f'Downloaded file: {total_length}/{total_length}')\n",
        "\n",
        "\n",
        "def load_inbreast_mask(mask_path, imshape=(4084, 3328)):\n",
        "    \"\"\"\n",
        "    This function loads a osirix xml region as a binary numpy array for INBREAST\n",
        "    dataset\n",
        "    @mask_path : Path to the xml file\n",
        "    @imshape : The shape of the image as an array e.g. [4084, 3328]\n",
        "    return: numpy array where positions in the roi are assigned a value of 1.\n",
        "    \"\"\"\n",
        "\n",
        "    mask = np.zeros(imshape)\n",
        "    with open(mask_path, 'rb') as mask_file:\n",
        "        plist_dict = plistlib.load(mask_file, fmt=plistlib.FMT_XML)['Images'][0]\n",
        "        numRois = plist_dict['NumberOfROIs']\n",
        "        rois = plist_dict['ROIs']\n",
        "        assert len(rois) == numRois\n",
        "        for roi in rois:\n",
        "            numPoints = roi['NumberOfPoints']\n",
        "            points = roi['Point_px']\n",
        "            assert numPoints == len(points)\n",
        "            points = [eval(point) for point in points]\n",
        "            if len(points) <= 2:\n",
        "                for point in points:\n",
        "                    mask[int(point[1]), int(point[0])] = 1\n",
        "            else:\n",
        "                x, y = zip(*points)\n",
        "                col, row = np.array(x), np.array(y) ##x coord is the column coord in an image and y is the row\n",
        "                poly_x, poly_y = polygon(row, col, shape=imshape)\n",
        "                mask[poly_x, poly_y] = 1\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idugy5gAIo_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_data_dir = '/content/data'\n",
        "create_dir(root_data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpUFHwaFzBHF",
        "colab_type": "text"
      },
      "source": [
        "### MIAS Dataset Downloading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk0es7WvCbtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name = 'MIAS'\n",
        "home_url = 'http://peipa.essex.ac.uk/info/mias.html'\n",
        "download_url = 'http://peipa.essex.ac.uk/pix/mias/all-mias.tar.gz'\n",
        "filename = '/content/data/all-mias.tar.gz'\n",
        "\n",
        "# Create dataset directory\n",
        "dataset_path = os.path.join(root_data_dir, dataset_name)\n",
        "create_dir(dataset_path)\n",
        "\n",
        "# Download and extract dataset\n",
        "download(download_url, filename)\n",
        "shutil.unpack_archive(filename, dataset_path)\n",
        "os.remove(filename)\n",
        "\n",
        "# Convert images to JPG format\n",
        "mias_images = os.path.join(dataset_path, 'images')\n",
        "create_dir(mias_images)\n",
        "for file in os.listdir(dataset_path):\n",
        "    if file.endswith('.pgm'):\n",
        "        filepath = os.path.join(dataset_path, file)\n",
        "        dstpath = os.path.join(mias_images, file.replace('.pgm', '.jpg'))\n",
        "        img = Image.open(filepath)\n",
        "        img.convert('RGB').save(dstpath)\n",
        "        os.remove(filepath)\n",
        "\n",
        "# Convert labels to CSV format\n",
        "with open(os.path.join(dataset_path, 'Info.txt')) as f:\n",
        "    r = f.read()\n",
        "df = pd.read_csv(StringIO(r.split('='*65)[-2].strip()), \n",
        "                 sep=' ', \n",
        "                 header=None,\n",
        "                 names=['refname', 'tissue', 'abnormality', 'severity', 'x', 'y', 'radius'])\n",
        "annotation_path = os.path.join(dataset_path, 'annotations.csv')\n",
        "df.to_csv(annotation_path, index=False)\n",
        "df.head()\n",
        "\n",
        "# Cleanup\n",
        "os.remove(os.path.join(dataset_path, 'README'))\n",
        "os.remove(os.path.join(dataset_path, 'Info.txt'))\n",
        "os.remove(os.path.join(dataset_path, 'Licence.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipyuSpb0zGUX",
        "colab_type": "text"
      },
      "source": [
        "### INbreast dataset downloading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sIROXp8CD2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset_name = 'INbreast'\n",
        "# download_url = 'https://drive.google.com/file/d/19n-p9p9C0eCQA1ybm6wkMo-bbeccT_62/view?usp=sharing'\n",
        "# githuburl = 'https://github.com/wentaozhu/deep-mil-for-whole-mammogram-classification/issues/12'\n",
        "# archive_path = \"/content/drive/My Drive/Breast Cancer Detection/INbreast Release 1.0.zip\"\n",
        "\n",
        "# # download dataset and move to data directory\n",
        "# dataset_path = os.path.join(root_data_dir, dataset_name)\n",
        "# create_dir(dataset_path)\n",
        "# !unzip /content/drive/'My Drive'/'Breast Cancer Detection'/'INbreast Release 1.0.zip' -d /data > /log.txt\n",
        "\n",
        "# Preprocess images\n",
        "inbreast_dcm = '/data/INbreast Release 1.0/AllDICOMs'\n",
        "inbreast_imgs = '/content/data/INbreast/images'\n",
        "create_dir(inbreast_imgs)\n",
        "for file in os.listdir(inbreast_dcm):\n",
        "    if file.endswith('.dcm'):\n",
        "        ds = dicom.dcmread(os.path.join(inbreast_dcm, file), force=True)\n",
        "        dst_file = os.path.join(inbreast_imgs, file.replace('.dcm', '.jpg')) \n",
        "        Image.fromarray(ds.pixel_array.astype('uint8')).save(dst_file)\n",
        "\n",
        "# Preprocess labels\n",
        "df = pd.read_excel(os.path.join('/data/INbreast Release 1.0', 'INbreast.xls'))\n",
        "replacing = {'Lesion Annotation Status': {'No annotation (Normal)': 'no', 'no annotation (normal)': 'no', 'Spiculated Region': 'yes', np.nan: 'yes'}}\n",
        "df = df.dropna(subset=['File Name']).replace(replacing)\n",
        "df['File Name'] = df['File Name'].astype(int)\n",
        "df.to_csv(os.path.join(dataset_path, 'labels.csv'), index=False)\n",
        "df.head()\n",
        "\n",
        "# Preprocess annotations\n",
        "annotations = [] \n",
        "masks_path = os.path.join(dataset_path, 'masks')\n",
        "create_dir(masks_path)\n",
        "annotation_file_ids = df[df['Lesion Annotation Status'] == 'yes']['File Name'].astype(str).to_list()\n",
        "for _id in annotation_file_ids:\n",
        "  # Load annotation file\n",
        "  inbreast_xml = '/data/INbreast Release 1.0/AllXML'\n",
        "  xml_path = [os.path.join(inbreast_xml, f) for f in os.listdir(inbreast_xml) if f.startswith(str(_id))][0]\n",
        "  # Load image file\n",
        "  image_path = [os.path.join(inbreast_imgs, f) for f in os.listdir(inbreast_imgs) if f.startswith(str(_id))][0]\n",
        "  image = cv2.imread(image_path)\n",
        "  # Create mask from annotation and save it\n",
        "  mask = load_inbreast_mask(xml_path, image.shape[:2])\n",
        "  cv2.imwrite(os.path.join(masks_path, str(_id) + '_mask.jpg'), mask*255)\n",
        "  # Find contours\n",
        "  contours, hierarchy = cv2.findContours((mask*255).astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  for cnt in contours:\n",
        "    # Approximate contour bounding box\n",
        "    epsilon = 0.01*cv2.arcLength(cnt, True)\n",
        "    approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
        "    x,y,w,h = cv2.boundingRect(cnt)\n",
        "    annotations.append((_id, x, y, x+w, y+h))\n",
        "\n",
        "# Create bounding box annotation dataframe\n",
        "df_annotations = pd.DataFrame.from_records(annotations, columns =['fileid', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
        "df_annotations.to_csv(os.path.join(dataset_path, 'annotations.csv'), index=False)\n",
        "\n",
        "# Cleanup\n",
        "!rm -rf /data/'INbreast Release 1.0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WjWUahu46ij",
        "colab_type": "text"
      },
      "source": [
        "### Finalizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSwzgXQVD3Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!zip -r /content/drive/'My Drive'/'Breast Cancer Detection'/breast_cancer_data.zip data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kQUMsH6KMJ3",
        "colab_type": "code",
        "outputId": "e56950c0-716f-4e63-9ce8-8c5f80a7b83d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf data\n",
        "!rm breast_cancer_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'breast_cancer_data.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcrBNK_VKFFz",
        "colab_type": "text"
      },
      "source": [
        "## Set up Models: Deep Convolutional Neural Networks for breast cancer screening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgJXlBtvjUEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_base_model(base, input_shape):\n",
        "\n",
        "    if base == 'VGG16':\n",
        "        # Create the base model from the pre-trained model VGG16\n",
        "        base_model = tf.keras.applications.VGG16(input_shape=input_shape,\n",
        "                                                include_top=False,\n",
        "                                                weights='imagenet')\n",
        "    elif base == 'InceptionV3':\n",
        "        # Create the base model from the pre-trained model Inception V3\n",
        "        base_model = tf.keras.applications.InceptionV3(input_shape=input_shape,\n",
        "                                                      include_top=False,\n",
        "                                                      weights='imagenet')\n",
        "    elif base == 'ResNet50':\n",
        "        # Create the base model from the pre-trained model ResNet50\n",
        "        base_model = tf.keras.applications.ResNet50(input_shape=input_shape,\n",
        "                                                    include_top=False,\n",
        "                                                    weights='imagenet')\n",
        "        \n",
        "    base_model.trainable = False\n",
        "\n",
        "    return base_model\n",
        "\n",
        "def create_model(base_model, num_classes):\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "      base_model,\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(256, \n",
        "                            activation='relu', \n",
        "                            kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dense(128, \n",
        "                            activation='relu',\n",
        "                            kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(64, \n",
        "                            activation='relu',\n",
        "                            kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dense(32, \n",
        "                            activation='relu',\n",
        "                            kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "def freeze_layers(base_model, base, finetune_blocks):\n",
        "\n",
        "    block_mapping = {\n",
        "        'VGG16': {\n",
        "            0: None,\n",
        "            1: 7,\n",
        "            2: 11,\n",
        "            3: 15,\n",
        "        },\n",
        "\n",
        "        'InceptionV3': {\n",
        "            0: None,\n",
        "            1: 219,\n",
        "            2: 494,\n",
        "            3: 15\n",
        "        },\n",
        "\n",
        "         'ResNet50': {\n",
        "            0: None,\n",
        "            1: 229,\n",
        "            2: 249,\n",
        "            3: 279\n",
        "        },             \n",
        "    }\n",
        "\n",
        "    # Unfreeze all layers\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Fine-tune from this layer onwards\n",
        "    fine_tune_at = block_mapping[base][finetune_blocks]\n",
        "\n",
        "    # Freeze all the layers before the `fine_tune_at` layer\n",
        "    for layer in base_model.layers[:fine_tune_at]:\n",
        "      layer.trainable =  False\n",
        "    \n",
        "    return base_model\n",
        "\n",
        "def load_data(train_df, valid_df, xcol, ycol, img_size, batch_size):\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.25,\n",
        "        height_shift_range=0.25,\n",
        "        shear_range=0.5,\n",
        "        zoom_range=[0.5, 1.5],\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train_df,\n",
        "        x_col = xcol,\n",
        "        y_col = ycol,\n",
        "        target_size = (img_size, img_size),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = 'categorical')\n",
        "\n",
        "    valid_generator = validation_datagen.flow_from_dataframe(\n",
        "        dataframe = valid_df,\n",
        "        x_col = xcol,\n",
        "        y_col = ycol,\n",
        "        target_size = (img_size, img_size),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = 'categorical')\n",
        "\n",
        "    return train_generator, valid_generator\n",
        "  \n",
        "def compile_model(model, base_lr=0.0001):\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=base_lr),\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                          monitor='val_loss',\n",
        "                          factor=0.1,\n",
        "                          patience=10,\n",
        "                          min_delta=0.0001,\n",
        "                          verbose=1,\n",
        "                          min_lr=0.0000001\n",
        "                          )\n",
        "\n",
        "def train_model(params):\n",
        "\n",
        "    batch_size = params['batch_size']\n",
        "    img_size = params['img_size']\n",
        "    img_shape = (img_size, img_size, 3)\n",
        "    num_classes = params['num_classes']\n",
        "    epochs = params['epochs']\n",
        "    base_lr = params['base_lr']\n",
        "    base = params['base']\n",
        "    finetune_blocks = params['finetune_blocks']\n",
        "\n",
        "\n",
        "    # FOR MIAS DATASET\n",
        "    if params['dataset'] == 'MIAS':\n",
        "        xcol = 'dstpath'\n",
        "        ycol = 'severity'\n",
        "        df = pd.read_csv('/content/data/MIAS/annotations0.csv')\n",
        "        df_train = pd.concat([df[df['severity'] == 'B'][:-7], \n",
        "                              df[df['severity'] == 'M'][:-7]])\n",
        "        df_valid = pd.concat([df[df['severity'] == 'B'][-12:], \n",
        "                              df[df['severity'] == 'M'][-12:]])\n",
        "    # FOR INBREAST DATASET\n",
        "    elif params['dataset'] == 'INbreast':\n",
        "        xcol = 'filepath'\n",
        "        ycol = 'cancer'\n",
        "        df = pd.read_csv('/content/data/INbreast/annotations0.csv')\n",
        "        df_train = pd.concat([df[df['cancer'] == 0][:-40], \n",
        "                              df[df['cancer'] == 1][:-200]])\n",
        "        df_valid = pd.concat([df[df['cancer'] == 1][-40:], \n",
        "                              df[df['cancer'] == 0][-200:]])\n",
        "\n",
        "    train_gen, valid_gen = load_data(df_train,\n",
        "                                    df_valid,\n",
        "                                    xcol,\n",
        "                                    ycol,\n",
        "                                    img_size,\n",
        "                                    batch_size)\n",
        "\n",
        "\n",
        "\n",
        "    base_model = create_base_model(base, img_shape)\n",
        "    base_model = freeze_layers(base_model, base, finetune_blocks)\n",
        "    model = create_model(base_model, num_classes)\n",
        "    model = compile_model(model, base_lr)\n",
        "\n",
        "    history = model.fit(\n",
        "                    train_gen,\n",
        "                    steps_per_epoch = train_gen.samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = valid_gen,\n",
        "                    validation_steps = valid_gen.samples//batch_size,\n",
        "                    callbacks = [reduce_lr]\n",
        "                    )\n",
        "    return history\n",
        "\n",
        "def plot(hist):\n",
        "    plt.plot(hist.epoch, hist.history['val_loss'])\n",
        "    plt.plot(hist.epoch, hist.history['loss'])\n",
        "    plt.xlabel('epochs'); plt.ylabel('loss'); plt.legend(['training loss', 'validation loss'])\n",
        "    plt.show()\n",
        "    plt.plot(hist.epoch, hist.history['val_accuracy'])\n",
        "    plt.plot(hist.epoch, hist.history['accuracy'])\n",
        "    plt.xlabel('epochs'); plt.ylabel('accuracy'); plt.legend(['training acc', 'validation acc'])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woeBaByvn18w",
        "colab_type": "text"
      },
      "source": [
        "## Train MIAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C2CzK7woe_t",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmVEiX4-Eomp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir('/content/data/MIAS/cropped'):\n",
        "    os.makedirs('/content/data/MIAS/cropped')\n",
        "df = pd.read_csv('/content/data/MIAS/annotations.csv')\n",
        "df['imgpath'] = '/content/data/MIAS/images/' + df['refname'] + '.jpg'\n",
        "df['dstpath'] = [s.replace('/images/', '/cropped/') for s in df.imgpath.to_list()]\n",
        "df_mod = df.dropna(subset=['x'])\n",
        "df_mod.to_csv('/content/data/MIAS/annotations0.csv', index=False)\n",
        "for row in df_mod.itertuples():\n",
        "    if not pd.isna(row.radius):\n",
        "        img = cv2.imread(row.imgpath)\n",
        "        height, width = img.shape[:2]\n",
        "        xc, yc = int(row.x), int(row.y)\n",
        "        xmin = max(xc - (224/2), 0)\n",
        "        xmax = min(xc + (224/2), width)\n",
        "        xmin += (224/2) - (xmax - xc)\n",
        "        xmax += (224/2) - (xc - xmin)\n",
        "        ymin = max(yc - (224/2), 0)\n",
        "        ymax = min(yc + (224/2), height)\n",
        "        ymin += (224/2) - (ymax-yc)\n",
        "        ymax += (224/2) - (yc - ymin)\n",
        "        xmin, xmax, ymin, ymax = int(xmin), int(xmax), int(ymin), int(ymax)\n",
        "        img = img[ymin:ymax, xmin:xmax]\n",
        "        cv2.imwrite(row.dstpath, img)\n",
        "        # x_min = int(row['x'])- int(1.2*int(row['radius']))\n",
        "        # x_max = int(row['x'])+int(1.2*int(row['radius']))\n",
        "        # y_min = int(row['y'])-int(1.2*int(row['radius']))\n",
        "        # y_max = int(row['y'])+int(1.2*int(row['radius']))\n",
        "        # xmin = min([x_min, 0])\n",
        "        # xmax = max([x_max, img.shape[0]])\n",
        "        # ymin = min([y_min, 0])\n",
        "        # ymax = max([y_max, img.shape[1]])\n",
        "        # img = img[xmin:xmax, ymin:ymax]\n",
        "        # cv2.imwrite(row['imgpath'], img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnLihkMHoiIB",
        "colab_type": "text"
      },
      "source": [
        "### Finetune 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RilxfLSh_fHW",
        "colab_type": "code",
        "outputId": "4e5f2b2e-fa1a-4a54-f78c-93e71981bb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hyperparameters = {\n",
        "    'img_size': 224,\n",
        "    'num_classes': 2,\n",
        "    'base': 'InceptionV3',\n",
        "    'finetune_blocks': 0,\n",
        "    'base_lr': 0.0001,\n",
        "    'epochs': 90,\n",
        "    'batch_size': 16,\n",
        "    'dataset': 'MIAS'\n",
        "}\n",
        "\n",
        "print(' ======== VGG16 ======== ')\n",
        "hyperparameters['base'] = 'VGG16'\n",
        "hist_vgg_0 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== ResNet50 ======== ')\n",
        "hyperparameters['base'] = 'ResNet50'\n",
        "hist_r50_0 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== InceptionV3 ======== ')\n",
        "hyperparameters['base'] = 'InceptionV3'\n",
        "hist_iv3_0 = train_model(hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ======== VGG16 ======== \n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Found 23 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"dstpath\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"dstpath\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "6/6 [==============================] - 2s 253ms/step - loss: 8.7824 - accuracy: 0.4896 - val_loss: 8.7254 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7389 - accuracy: 0.5169 - val_loss: 8.7229 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7726 - accuracy: 0.4719 - val_loss: 8.7163 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7416 - accuracy: 0.4607 - val_loss: 8.7079 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7134 - accuracy: 0.5843 - val_loss: 8.7193 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7430 - accuracy: 0.5169 - val_loss: 8.7235 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.6627 - accuracy: 0.5843 - val_loss: 8.6951 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7365 - accuracy: 0.5521 - val_loss: 8.7417 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "6/6 [==============================] - 1s 209ms/step - loss: 8.7343 - accuracy: 0.5281 - val_loss: 8.7071 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.6937 - accuracy: 0.6292 - val_loss: 8.7055 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7312 - accuracy: 0.4831 - val_loss: 8.7190 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7604 - accuracy: 0.5730 - val_loss: 8.6933 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7334 - accuracy: 0.5169 - val_loss: 8.7046 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.6735 - accuracy: 0.6180 - val_loss: 8.7076 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7661 - accuracy: 0.4688 - val_loss: 8.7215 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.7268 - accuracy: 0.5281 - val_loss: 8.7361 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 17/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7524 - accuracy: 0.4719 - val_loss: 8.7171 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 18/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7033 - accuracy: 0.5843 - val_loss: 8.7175 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 19/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7523 - accuracy: 0.5281 - val_loss: 8.7235 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 20/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.6962 - accuracy: 0.5506 - val_loss: 8.7167 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 21/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7415 - accuracy: 0.5169 - val_loss: 8.7260 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 22/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7070 - accuracy: 0.5833\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7070 - accuracy: 0.5833 - val_loss: 8.6987 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 23/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.6595 - accuracy: 0.6404 - val_loss: 8.7200 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 24/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7486 - accuracy: 0.5169 - val_loss: 8.7212 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 25/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7527 - accuracy: 0.4607 - val_loss: 8.7124 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 26/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7121 - accuracy: 0.5955 - val_loss: 8.7214 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 27/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7159 - accuracy: 0.5843 - val_loss: 8.7253 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 28/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.6829 - accuracy: 0.6067 - val_loss: 8.7151 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 29/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7133 - accuracy: 0.5938 - val_loss: 8.7170 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 30/90\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 8.7313 - accuracy: 0.5056 - val_loss: 8.7198 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 31/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.6991 - accuracy: 0.6180 - val_loss: 8.7300 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 32/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7097 - accuracy: 0.5955\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7097 - accuracy: 0.5955 - val_loss: 8.6980 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 33/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7267 - accuracy: 0.4944 - val_loss: 8.7035 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 34/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7141 - accuracy: 0.5393 - val_loss: 8.7091 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 35/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7146 - accuracy: 0.5618 - val_loss: 8.7085 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 36/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7232 - accuracy: 0.5833 - val_loss: 8.7148 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 37/90\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 8.6806 - accuracy: 0.5730 - val_loss: 8.7200 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 38/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7621 - accuracy: 0.4944 - val_loss: 8.7204 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 39/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7093 - accuracy: 0.5730 - val_loss: 8.7093 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 40/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.6828 - accuracy: 0.6292 - val_loss: 8.7029 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 41/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.6976 - accuracy: 0.5506 - val_loss: 8.7099 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 42/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.6865 - accuracy: 0.5618\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.6865 - accuracy: 0.5618 - val_loss: 8.7136 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 43/90\n",
            "6/6 [==============================] - 1s 208ms/step - loss: 8.7320 - accuracy: 0.5000 - val_loss: 8.7225 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 44/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.6820 - accuracy: 0.6067 - val_loss: 8.7193 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 45/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7194 - accuracy: 0.6067 - val_loss: 8.7243 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 46/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7246 - accuracy: 0.5169 - val_loss: 8.6998 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 47/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.6824 - accuracy: 0.5730 - val_loss: 8.7046 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 48/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7278 - accuracy: 0.5169 - val_loss: 8.7285 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 49/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7225 - accuracy: 0.5393 - val_loss: 8.7010 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 50/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7192 - accuracy: 0.5625 - val_loss: 8.7066 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 51/90\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 8.7467 - accuracy: 0.5281 - val_loss: 8.6991 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 52/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7279 - accuracy: 0.5281\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.7279 - accuracy: 0.5281 - val_loss: 8.7160 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 53/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7934 - accuracy: 0.4494 - val_loss: 8.7015 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 54/90\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.7177 - accuracy: 0.6180 - val_loss: 8.7112 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 55/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7214 - accuracy: 0.5281 - val_loss: 8.7051 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 56/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7057 - accuracy: 0.5393 - val_loss: 8.7050 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 57/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7115 - accuracy: 0.5938 - val_loss: 8.7173 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 58/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7313 - accuracy: 0.5281 - val_loss: 8.7089 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 59/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7162 - accuracy: 0.5730 - val_loss: 8.7074 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 60/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7502 - accuracy: 0.5955 - val_loss: 8.7127 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 61/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7218 - accuracy: 0.5506 - val_loss: 8.6989 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 62/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7426 - accuracy: 0.5281\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7426 - accuracy: 0.5281 - val_loss: 8.7179 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 63/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7173 - accuracy: 0.5169 - val_loss: 8.7188 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 64/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7002 - accuracy: 0.5000 - val_loss: 8.7137 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 65/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7558 - accuracy: 0.4831 - val_loss: 8.6963 - val_accuracy: 0.6875 - lr: 1.0000e-07\n",
            "Epoch 66/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7207 - accuracy: 0.5506 - val_loss: 8.7065 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 67/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7152 - accuracy: 0.5730 - val_loss: 8.7136 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 68/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7207 - accuracy: 0.5506 - val_loss: 8.7131 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 69/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7240 - accuracy: 0.5843 - val_loss: 8.7176 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 70/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7092 - accuracy: 0.5393 - val_loss: 8.7290 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 71/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7137 - accuracy: 0.5312 - val_loss: 8.7186 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 72/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7211 - accuracy: 0.5843\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7211 - accuracy: 0.5843 - val_loss: 8.7174 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 73/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7208 - accuracy: 0.5393 - val_loss: 8.7149 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 74/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7195 - accuracy: 0.5843 - val_loss: 8.7006 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 75/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7077 - accuracy: 0.6404 - val_loss: 8.7152 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 76/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7120 - accuracy: 0.5618 - val_loss: 8.7289 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 77/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7154 - accuracy: 0.6404 - val_loss: 8.7152 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 78/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7044 - accuracy: 0.5625 - val_loss: 8.7053 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 79/90\n",
            "6/6 [==============================] - 1s 209ms/step - loss: 8.6886 - accuracy: 0.5730 - val_loss: 8.7156 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 80/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7026 - accuracy: 0.5169 - val_loss: 8.6976 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 81/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.6899 - accuracy: 0.6292 - val_loss: 8.7250 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 82/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7518 - accuracy: 0.5169\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7518 - accuracy: 0.5169 - val_loss: 8.7027 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 83/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.6858 - accuracy: 0.5506 - val_loss: 8.7203 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 84/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7058 - accuracy: 0.5955 - val_loss: 8.7255 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 85/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.6842 - accuracy: 0.5521 - val_loss: 8.7240 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 86/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7431 - accuracy: 0.5056 - val_loss: 8.7087 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 87/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.6929 - accuracy: 0.6404 - val_loss: 8.7274 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 88/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7579 - accuracy: 0.4831 - val_loss: 8.7050 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 89/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.6935 - accuracy: 0.6067 - val_loss: 8.7197 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 90/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7124 - accuracy: 0.4831 - val_loss: 8.6955 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            " ======== ResNet50 ======== \n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Found 23 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/90\n",
            "6/6 [==============================] - 2s 380ms/step - loss: 8.9036 - accuracy: 0.5000 - val_loss: 8.7725 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.8195 - accuracy: 0.5506 - val_loss: 8.7687 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.8074 - accuracy: 0.5843 - val_loss: 8.7977 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.8127 - accuracy: 0.5618 - val_loss: 8.7629 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7607 - accuracy: 0.5843 - val_loss: 8.7522 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.8477 - accuracy: 0.5056 - val_loss: 8.7946 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.8023 - accuracy: 0.5730 - val_loss: 8.7951 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7978 - accuracy: 0.4792 - val_loss: 8.8266 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7680 - accuracy: 0.5730 - val_loss: 8.9221 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7848 - accuracy: 0.5506 - val_loss: 8.7931 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7803 - accuracy: 0.5730 - val_loss: 8.8398 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.8097 - accuracy: 0.4831 - val_loss: 8.8500 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.8478 - accuracy: 0.4831 - val_loss: 8.7682 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.8094 - accuracy: 0.5169 - val_loss: 8.7703 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7806 - accuracy: 0.5417\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7806 - accuracy: 0.5417 - val_loss: 8.7742 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7913 - accuracy: 0.5056 - val_loss: 8.7580 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 17/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.8191 - accuracy: 0.5056 - val_loss: 8.8077 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 18/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7603 - accuracy: 0.5955 - val_loss: 8.8064 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 19/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7948 - accuracy: 0.5169 - val_loss: 8.7901 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 20/90\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.7766 - accuracy: 0.5730 - val_loss: 8.7896 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 21/90\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 8.7988 - accuracy: 0.4831 - val_loss: 8.7585 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 22/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7663 - accuracy: 0.5312 - val_loss: 8.7724 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 23/90\n",
            "6/6 [==============================] - 1s 208ms/step - loss: 8.7625 - accuracy: 0.4944 - val_loss: 8.7572 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 24/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7857 - accuracy: 0.5056 - val_loss: 8.7586 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 25/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7673 - accuracy: 0.6067\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7673 - accuracy: 0.6067 - val_loss: 8.7877 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 26/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7796 - accuracy: 0.5169 - val_loss: 8.7707 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 27/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7711 - accuracy: 0.5730 - val_loss: 8.7753 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 28/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.8147 - accuracy: 0.4944 - val_loss: 8.7870 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 29/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7804 - accuracy: 0.5312 - val_loss: 8.7874 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 30/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7356 - accuracy: 0.6404 - val_loss: 8.8011 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 31/90\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.8165 - accuracy: 0.4944 - val_loss: 8.7854 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 32/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7384 - accuracy: 0.7079 - val_loss: 8.7573 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 33/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7908 - accuracy: 0.5281 - val_loss: 8.7730 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 34/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7402 - accuracy: 0.5506 - val_loss: 8.7600 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 35/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7197 - accuracy: 0.6742\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.7197 - accuracy: 0.6742 - val_loss: 8.8003 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 36/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7829 - accuracy: 0.5312 - val_loss: 8.7702 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 37/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.8087 - accuracy: 0.5169 - val_loss: 8.7870 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 38/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7568 - accuracy: 0.6292 - val_loss: 8.7728 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 39/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.8021 - accuracy: 0.4944 - val_loss: 8.8151 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 40/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7504 - accuracy: 0.6180 - val_loss: 8.7718 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 41/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7737 - accuracy: 0.5730 - val_loss: 8.7998 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 42/90\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 8.8201 - accuracy: 0.5393 - val_loss: 8.7862 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 43/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.7681 - accuracy: 0.5729 - val_loss: 8.7613 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 44/90\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 8.7922 - accuracy: 0.5506 - val_loss: 8.7598 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 45/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7862 - accuracy: 0.5843\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7862 - accuracy: 0.5843 - val_loss: 8.7577 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 46/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8313 - accuracy: 0.5169 - val_loss: 8.7584 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 47/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7379 - accuracy: 0.6180 - val_loss: 8.7455 - val_accuracy: 0.6875 - lr: 1.0000e-07\n",
            "Epoch 48/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7744 - accuracy: 0.5730 - val_loss: 8.8013 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 49/90\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 8.8219 - accuracy: 0.4831 - val_loss: 8.7843 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 50/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7735 - accuracy: 0.5104 - val_loss: 8.8021 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 51/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7526 - accuracy: 0.5955 - val_loss: 8.7723 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 52/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7774 - accuracy: 0.5393 - val_loss: 8.8009 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 53/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7768 - accuracy: 0.5393 - val_loss: 8.8028 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 54/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7862 - accuracy: 0.5393 - val_loss: 8.7861 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 55/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7589 - accuracy: 0.6517 - val_loss: 8.8011 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 56/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7814 - accuracy: 0.5506 - val_loss: 8.7890 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 57/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8046 - accuracy: 0.5208\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.8046 - accuracy: 0.5208 - val_loss: 8.7715 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 58/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.8066 - accuracy: 0.5056 - val_loss: 8.7865 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 59/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7485 - accuracy: 0.6404 - val_loss: 8.7717 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 60/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7784 - accuracy: 0.5843 - val_loss: 8.7727 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 61/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7621 - accuracy: 0.6292 - val_loss: 8.7593 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 62/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.8192 - accuracy: 0.4831 - val_loss: 8.8149 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 63/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7509 - accuracy: 0.5618 - val_loss: 8.7743 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 64/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7841 - accuracy: 0.5938 - val_loss: 8.7998 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 65/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7694 - accuracy: 0.6404 - val_loss: 8.7703 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 66/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7802 - accuracy: 0.5393 - val_loss: 8.7702 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 67/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7642 - accuracy: 0.5281\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7642 - accuracy: 0.5281 - val_loss: 8.7747 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 68/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7986 - accuracy: 0.5730 - val_loss: 8.7875 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 69/90\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.8105 - accuracy: 0.4944 - val_loss: 8.7721 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 70/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7740 - accuracy: 0.5281 - val_loss: 8.8004 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 71/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7732 - accuracy: 0.6042 - val_loss: 8.7585 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 72/90\n",
            "6/6 [==============================] - 1s 209ms/step - loss: 8.7952 - accuracy: 0.5393 - val_loss: 8.7702 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 73/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7829 - accuracy: 0.5843 - val_loss: 8.7874 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 74/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.8019 - accuracy: 0.5056 - val_loss: 8.7722 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 75/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7722 - accuracy: 0.6180 - val_loss: 8.7979 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 76/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7812 - accuracy: 0.5506 - val_loss: 8.7718 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 77/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7771 - accuracy: 0.5393\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7771 - accuracy: 0.5393 - val_loss: 8.7729 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 78/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.8235 - accuracy: 0.4896 - val_loss: 8.7862 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 79/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7915 - accuracy: 0.5843 - val_loss: 8.7871 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 80/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7410 - accuracy: 0.6404 - val_loss: 8.7987 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 81/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7991 - accuracy: 0.5281 - val_loss: 8.7757 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 82/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7777 - accuracy: 0.5169 - val_loss: 8.7704 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 83/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7740 - accuracy: 0.5730 - val_loss: 8.7871 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 84/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7776 - accuracy: 0.5843 - val_loss: 8.7748 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 85/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7707 - accuracy: 0.5208 - val_loss: 8.7717 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 86/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7791 - accuracy: 0.5843 - val_loss: 8.7994 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 87/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7459 - accuracy: 0.5506\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7459 - accuracy: 0.5506 - val_loss: 8.7582 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 88/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7986 - accuracy: 0.5955 - val_loss: 8.7704 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 89/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7794 - accuracy: 0.5843 - val_loss: 8.7857 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 90/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7911 - accuracy: 0.5056 - val_loss: 8.7702 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            " ======== InceptionV3 ======== \n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Found 23 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/90\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 8.7799 - accuracy: 0.4896 - val_loss: 8.7679 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.8740 - accuracy: 0.4270 - val_loss: 8.7547 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7851 - accuracy: 0.5056 - val_loss: 8.7535 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7989 - accuracy: 0.5169 - val_loss: 8.7903 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7704 - accuracy: 0.5730 - val_loss: 8.8037 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7924 - accuracy: 0.4719 - val_loss: 8.8241 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7795 - accuracy: 0.5506 - val_loss: 8.7224 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.8076 - accuracy: 0.4792 - val_loss: 8.7961 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7846 - accuracy: 0.5169 - val_loss: 8.7905 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7149 - accuracy: 0.5618 - val_loss: 8.7503 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7645 - accuracy: 0.5506 - val_loss: 8.7351 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7681 - accuracy: 0.5618 - val_loss: 8.8146 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.8286 - accuracy: 0.4831 - val_loss: 8.7425 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7738 - accuracy: 0.4831 - val_loss: 8.8065 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.8390 - accuracy: 0.4167 - val_loss: 8.7803 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7649 - accuracy: 0.5169 - val_loss: 8.7263 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 17/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7924 - accuracy: 0.4607\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7924 - accuracy: 0.4607 - val_loss: 8.7981 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 18/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7873 - accuracy: 0.4831 - val_loss: 8.8217 - val_accuracy: 0.3125 - lr: 1.0000e-05\n",
            "Epoch 19/90\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.7656 - accuracy: 0.5618 - val_loss: 8.7776 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 20/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7533 - accuracy: 0.5955 - val_loss: 8.7807 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 21/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7600 - accuracy: 0.5393 - val_loss: 8.7672 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 22/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7728 - accuracy: 0.5312 - val_loss: 8.7816 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 23/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7679 - accuracy: 0.5843 - val_loss: 8.7579 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 24/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7467 - accuracy: 0.6067 - val_loss: 8.7444 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 25/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7921 - accuracy: 0.4944 - val_loss: 8.7992 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 26/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.8105 - accuracy: 0.4494 - val_loss: 8.7670 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 27/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7773 - accuracy: 0.4719\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.7773 - accuracy: 0.4719 - val_loss: 8.7827 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 28/90\n",
            "6/6 [==============================] - 1s 180ms/step - loss: 8.7094 - accuracy: 0.5955 - val_loss: 8.7752 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 29/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7871 - accuracy: 0.5312 - val_loss: 8.7789 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 30/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7987 - accuracy: 0.5056 - val_loss: 8.7480 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 31/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7766 - accuracy: 0.5281 - val_loss: 8.7736 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 32/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.8212 - accuracy: 0.4494 - val_loss: 8.7792 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 33/90\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 8.7726 - accuracy: 0.4944 - val_loss: 8.8123 - val_accuracy: 0.3125 - lr: 1.0000e-06\n",
            "Epoch 34/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7719 - accuracy: 0.5281 - val_loss: 8.7882 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 35/90\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 8.7669 - accuracy: 0.5169 - val_loss: 8.7434 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 36/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7204 - accuracy: 0.6146 - val_loss: 8.7697 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 37/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7402 - accuracy: 0.5618\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7402 - accuracy: 0.5618 - val_loss: 8.7225 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 38/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7986 - accuracy: 0.5281 - val_loss: 8.8375 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 39/90\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 8.7837 - accuracy: 0.5281 - val_loss: 8.7461 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 40/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.8170 - accuracy: 0.4607 - val_loss: 8.7869 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 41/90\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 8.8044 - accuracy: 0.4270 - val_loss: 8.8037 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 42/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7322 - accuracy: 0.5955 - val_loss: 8.8126 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 43/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.8014 - accuracy: 0.5312 - val_loss: 8.7368 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 44/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.8256 - accuracy: 0.4831 - val_loss: 8.7442 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 45/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7565 - accuracy: 0.6404 - val_loss: 8.7279 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 46/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.8004 - accuracy: 0.5169 - val_loss: 8.7758 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 47/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7953 - accuracy: 0.5169\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7953 - accuracy: 0.5169 - val_loss: 8.7540 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 48/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7726 - accuracy: 0.5169 - val_loss: 8.7565 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 49/90\n",
            "6/6 [==============================] - 1s 181ms/step - loss: 8.8031 - accuracy: 0.4607 - val_loss: 8.8011 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 50/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.8307 - accuracy: 0.4792 - val_loss: 8.7731 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 51/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7719 - accuracy: 0.5506 - val_loss: 8.7680 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 52/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7301 - accuracy: 0.6067 - val_loss: 8.7142 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 53/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7503 - accuracy: 0.5730 - val_loss: 8.7861 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 54/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7734 - accuracy: 0.5393 - val_loss: 8.7582 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 55/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7884 - accuracy: 0.4719 - val_loss: 8.8066 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 56/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7805 - accuracy: 0.5393 - val_loss: 8.8035 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 57/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.8042 - accuracy: 0.4896 - val_loss: 8.7581 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 58/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.7666 - accuracy: 0.4944 - val_loss: 8.7723 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 59/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7829 - accuracy: 0.4944 - val_loss: 8.7287 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 60/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7799 - accuracy: 0.4831 - val_loss: 8.8143 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 61/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7731 - accuracy: 0.5169 - val_loss: 8.7695 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 62/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7791 - accuracy: 0.5169\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7791 - accuracy: 0.5169 - val_loss: 8.7594 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 63/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7912 - accuracy: 0.4270 - val_loss: 8.8048 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 64/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7906 - accuracy: 0.5312 - val_loss: 8.7599 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 65/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.8327 - accuracy: 0.4607 - val_loss: 8.7960 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 66/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7851 - accuracy: 0.4944 - val_loss: 8.8055 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 67/90\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 8.7544 - accuracy: 0.5393 - val_loss: 8.7469 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 68/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.8318 - accuracy: 0.4607 - val_loss: 8.7739 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 69/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7513 - accuracy: 0.5393 - val_loss: 8.7633 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 70/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7876 - accuracy: 0.4719 - val_loss: 8.8128 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 71/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7499 - accuracy: 0.5521 - val_loss: 8.7499 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 72/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7828 - accuracy: 0.5056\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7828 - accuracy: 0.5056 - val_loss: 8.7921 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 73/90\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.7918 - accuracy: 0.5056 - val_loss: 8.7879 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 74/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7783 - accuracy: 0.5056 - val_loss: 8.7705 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 75/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7641 - accuracy: 0.5730 - val_loss: 8.7669 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 76/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7144 - accuracy: 0.6517 - val_loss: 8.7822 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 77/90\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.7679 - accuracy: 0.5506 - val_loss: 8.7827 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 78/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7722 - accuracy: 0.5208 - val_loss: 8.7691 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 79/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7829 - accuracy: 0.4382 - val_loss: 8.7883 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 80/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7774 - accuracy: 0.5618 - val_loss: 8.7500 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 81/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7601 - accuracy: 0.5843 - val_loss: 8.7772 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 82/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7666 - accuracy: 0.5506\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7666 - accuracy: 0.5506 - val_loss: 8.7408 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 83/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7626 - accuracy: 0.5393 - val_loss: 8.7854 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 84/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7665 - accuracy: 0.5506 - val_loss: 8.7898 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 85/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.8013 - accuracy: 0.5104 - val_loss: 8.7708 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 86/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7549 - accuracy: 0.5618 - val_loss: 8.7711 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 87/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7357 - accuracy: 0.5506 - val_loss: 8.7381 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 88/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.8123 - accuracy: 0.4831 - val_loss: 8.8055 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 89/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7881 - accuracy: 0.5056 - val_loss: 8.7439 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 90/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7998 - accuracy: 0.5393 - val_loss: 8.7293 - val_accuracy: 0.5625 - lr: 1.0000e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u282D8mEok-u",
        "colab_type": "text"
      },
      "source": [
        "### Finetune 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FKclEbQGqnM",
        "colab_type": "code",
        "outputId": "d5c49f5e-238f-4efd-d27e-dbcf23221bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hyperparameters = {\n",
        "    'img_size': 224,\n",
        "    'num_classes': 2,\n",
        "    'base': 'InceptionV3',\n",
        "    'finetune_blocks': 1,\n",
        "    'base_lr': 0.0001,\n",
        "    'epochs': 90,\n",
        "    'batch_size': 16,\n",
        "    'dataset': 'MIAS'\n",
        "}\n",
        "\n",
        "print(' ======== VGG16 ======== ')\n",
        "hyperparameters['base'] = 'VGG16'\n",
        "hist_vgg_1 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== ResNet50 ======== ')\n",
        "hyperparameters['base'] = 'ResNet50'\n",
        "hist_r50_1 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== InceptionV3 ======== ')\n",
        "hyperparameters['base'] = 'InceptionV3'\n",
        "hist_iv3_1 = train_model(hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ======== VGG16 ======== \n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Found 23 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"dstpath\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"dstpath\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "6/6 [==============================] - 2s 255ms/step - loss: 8.7479 - accuracy: 0.5833 - val_loss: 8.7434 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 8.7757 - accuracy: 0.4494 - val_loss: 8.7432 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7710 - accuracy: 0.5281 - val_loss: 8.7531 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7532 - accuracy: 0.5056 - val_loss: 8.7506 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7538 - accuracy: 0.4944 - val_loss: 8.7410 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7479 - accuracy: 0.5169 - val_loss: 8.7367 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7353 - accuracy: 0.5618 - val_loss: 8.7833 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7552 - accuracy: 0.5625 - val_loss: 8.7350 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 8.7415 - accuracy: 0.5618 - val_loss: 8.7420 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7125 - accuracy: 0.6742 - val_loss: 8.7694 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7339 - accuracy: 0.5843 - val_loss: 8.7577 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7930 - accuracy: 0.4831 - val_loss: 8.7557 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7297 - accuracy: 0.5730 - val_loss: 8.7245 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7528 - accuracy: 0.5169 - val_loss: 8.7408 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 8.7452 - accuracy: 0.5208 - val_loss: 8.7075 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 8.7071 - accuracy: 0.6629 - val_loss: 8.7203 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 17/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7165 - accuracy: 0.5730 - val_loss: 8.7519 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 18/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7554 - accuracy: 0.5618 - val_loss: 8.7366 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 19/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7692 - accuracy: 0.5281 - val_loss: 8.7746 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 20/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7242 - accuracy: 0.6180 - val_loss: 8.7360 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 21/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7153 - accuracy: 0.6292 - val_loss: 8.7815 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 22/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7290 - accuracy: 0.5938 - val_loss: 8.7169 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 23/90\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 8.7766 - accuracy: 0.5393 - val_loss: 8.7721 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 24/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7080 - accuracy: 0.6517 - val_loss: 8.7787 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 25/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7479 - accuracy: 0.5056\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7479 - accuracy: 0.5056 - val_loss: 8.7781 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 26/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7546 - accuracy: 0.5281 - val_loss: 8.7781 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 27/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7328 - accuracy: 0.5281 - val_loss: 8.7789 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 28/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7390 - accuracy: 0.5506 - val_loss: 8.7330 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 29/90\n",
            "6/6 [==============================] - 1s 216ms/step - loss: 8.7360 - accuracy: 0.5833 - val_loss: 8.7537 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 30/90\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 8.7560 - accuracy: 0.5169 - val_loss: 8.8005 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 31/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7464 - accuracy: 0.5843 - val_loss: 8.7539 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 32/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7055 - accuracy: 0.6404 - val_loss: 8.7585 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 33/90\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 8.7628 - accuracy: 0.5169 - val_loss: 8.7755 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 34/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.7400 - accuracy: 0.5506 - val_loss: 8.7216 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 35/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7455 - accuracy: 0.5843\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7455 - accuracy: 0.5843 - val_loss: 8.7194 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 36/90\n",
            "6/6 [==============================] - 1s 214ms/step - loss: 8.7656 - accuracy: 0.5208 - val_loss: 8.7374 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 37/90\n",
            "6/6 [==============================] - 1s 222ms/step - loss: 8.7227 - accuracy: 0.5843 - val_loss: 8.7174 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 38/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7217 - accuracy: 0.6404 - val_loss: 8.7613 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 39/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7498 - accuracy: 0.5393 - val_loss: 8.7798 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 40/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.7346 - accuracy: 0.5506 - val_loss: 8.7379 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 41/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7440 - accuracy: 0.5730 - val_loss: 8.7589 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 42/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7405 - accuracy: 0.5618 - val_loss: 8.7971 - val_accuracy: 0.3750 - lr: 1.0000e-06\n",
            "Epoch 43/90\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 8.7409 - accuracy: 0.5625 - val_loss: 8.7777 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 44/90\n",
            "6/6 [==============================] - 1s 219ms/step - loss: 8.7046 - accuracy: 0.5730 - val_loss: 8.7143 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 45/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7267 - accuracy: 0.6067\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7267 - accuracy: 0.6067 - val_loss: 8.7401 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 46/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7683 - accuracy: 0.5056 - val_loss: 8.7330 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 47/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7431 - accuracy: 0.5393 - val_loss: 8.7978 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 48/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7212 - accuracy: 0.5730 - val_loss: 8.7422 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 49/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7537 - accuracy: 0.5618 - val_loss: 8.7553 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 50/90\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 8.7448 - accuracy: 0.5625 - val_loss: 8.7742 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 51/90\n",
            "6/6 [==============================] - 1s 222ms/step - loss: 8.7467 - accuracy: 0.5056 - val_loss: 8.7444 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 52/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7298 - accuracy: 0.5843 - val_loss: 8.7138 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 53/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7546 - accuracy: 0.5506 - val_loss: 8.7582 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 54/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7578 - accuracy: 0.5169 - val_loss: 8.6778 - val_accuracy: 0.7500 - lr: 1.0000e-07\n",
            "Epoch 55/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7428 - accuracy: 0.5618 - val_loss: 8.7814 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 56/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7387 - accuracy: 0.5955 - val_loss: 8.7553 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 57/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7469 - accuracy: 0.5625 - val_loss: 8.7554 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 58/90\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 8.7640 - accuracy: 0.5506 - val_loss: 8.7542 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 59/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7466 - accuracy: 0.5618 - val_loss: 8.7978 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 60/90\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 8.7537 - accuracy: 0.5506 - val_loss: 8.7183 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 61/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7405 - accuracy: 0.5506 - val_loss: 8.7824 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 62/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7479 - accuracy: 0.4607 - val_loss: 8.7779 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 63/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7102 - accuracy: 0.5955 - val_loss: 8.7400 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 64/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7349 - accuracy: 0.5625\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 8.7349 - accuracy: 0.5625 - val_loss: 8.7599 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 65/90\n",
            "6/6 [==============================] - 1s 220ms/step - loss: 8.7895 - accuracy: 0.4270 - val_loss: 8.7372 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 66/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7728 - accuracy: 0.5056 - val_loss: 8.7362 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 67/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7463 - accuracy: 0.5506 - val_loss: 8.7572 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 68/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7223 - accuracy: 0.6067 - val_loss: 8.7155 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 69/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7383 - accuracy: 0.5393 - val_loss: 8.7379 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 70/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7502 - accuracy: 0.5393 - val_loss: 8.7523 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 71/90\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 8.7500 - accuracy: 0.5625 - val_loss: 8.7406 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 72/90\n",
            "6/6 [==============================] - 1s 222ms/step - loss: 8.7268 - accuracy: 0.6067 - val_loss: 8.7361 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 73/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7467 - accuracy: 0.5730 - val_loss: 8.7200 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 74/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7356 - accuracy: 0.5730\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 8.7356 - accuracy: 0.5730 - val_loss: 8.7583 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 75/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7441 - accuracy: 0.5506 - val_loss: 8.7552 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 76/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7394 - accuracy: 0.5169 - val_loss: 8.7527 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 77/90\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.7383 - accuracy: 0.5281 - val_loss: 8.7613 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 78/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7311 - accuracy: 0.5417 - val_loss: 8.7625 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 79/90\n",
            "6/6 [==============================] - 1s 220ms/step - loss: 8.7631 - accuracy: 0.4944 - val_loss: 8.7573 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 80/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7244 - accuracy: 0.5955 - val_loss: 8.8025 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 81/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7340 - accuracy: 0.6180 - val_loss: 8.7810 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 82/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7076 - accuracy: 0.5843 - val_loss: 8.6949 - val_accuracy: 0.6875 - lr: 1.0000e-07\n",
            "Epoch 83/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7284 - accuracy: 0.5506 - val_loss: 8.7635 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 84/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7608 - accuracy: 0.4944\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7608 - accuracy: 0.4944 - val_loss: 8.7827 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 85/90\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 8.7475 - accuracy: 0.5729 - val_loss: 8.7183 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 86/90\n",
            "6/6 [==============================] - 1s 224ms/step - loss: 8.7236 - accuracy: 0.6292 - val_loss: 8.7794 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 87/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7250 - accuracy: 0.5730 - val_loss: 8.7362 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 88/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7563 - accuracy: 0.5393 - val_loss: 8.7402 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 89/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7164 - accuracy: 0.6067 - val_loss: 8.7758 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 90/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7236 - accuracy: 0.5843 - val_loss: 8.7775 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            " ======== ResNet50 ======== \n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Found 23 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/90\n",
            "6/6 [==============================] - 2s 377ms/step - loss: 8.8381 - accuracy: 0.5208 - val_loss: 8.8003 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7812 - accuracy: 0.5955 - val_loss: 8.7673 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8080 - accuracy: 0.5281 - val_loss: 8.8017 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7563 - accuracy: 0.5843 - val_loss: 8.7896 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.8119 - accuracy: 0.4831 - val_loss: 8.7769 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.8172 - accuracy: 0.5955 - val_loss: 8.7738 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.8146 - accuracy: 0.4944 - val_loss: 8.7874 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.7704 - accuracy: 0.5521 - val_loss: 8.7835 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7792 - accuracy: 0.6067 - val_loss: 8.7645 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7830 - accuracy: 0.5618 - val_loss: 8.7796 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.8059 - accuracy: 0.5169 - val_loss: 8.7759 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7754 - accuracy: 0.5393 - val_loss: 8.7598 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7906 - accuracy: 0.5506 - val_loss: 8.7726 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7882 - accuracy: 0.4944 - val_loss: 8.7634 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7848 - accuracy: 0.5312 - val_loss: 8.7777 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.8114 - accuracy: 0.5618 - val_loss: 8.7769 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 17/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7665 - accuracy: 0.5281 - val_loss: 8.7768 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 18/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7832 - accuracy: 0.5393 - val_loss: 8.7695 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 19/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7936 - accuracy: 0.5281 - val_loss: 8.7742 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 20/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.8001 - accuracy: 0.4719 - val_loss: 8.7829 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 21/90\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.7826 - accuracy: 0.5506 - val_loss: 8.7814 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 22/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7896 - accuracy: 0.5104\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7896 - accuracy: 0.5104 - val_loss: 8.7723 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 23/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7673 - accuracy: 0.5506 - val_loss: 8.7907 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 24/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7932 - accuracy: 0.5393 - val_loss: 8.7700 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 25/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7784 - accuracy: 0.5506 - val_loss: 8.7741 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 26/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7526 - accuracy: 0.5730 - val_loss: 8.7806 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 27/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.8121 - accuracy: 0.5056 - val_loss: 8.7899 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 28/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7587 - accuracy: 0.5843 - val_loss: 8.7965 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 29/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7587 - accuracy: 0.5208 - val_loss: 8.7718 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 30/90\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 8.7610 - accuracy: 0.5843 - val_loss: 8.7992 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 31/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7758 - accuracy: 0.5281 - val_loss: 8.7884 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 32/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7530 - accuracy: 0.5730\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7530 - accuracy: 0.5730 - val_loss: 8.7874 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 33/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7689 - accuracy: 0.5955 - val_loss: 8.7717 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 34/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.8073 - accuracy: 0.5281 - val_loss: 8.7690 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 35/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7708 - accuracy: 0.5955 - val_loss: 8.7703 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 36/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7794 - accuracy: 0.5521 - val_loss: 8.7734 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 37/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7766 - accuracy: 0.5281 - val_loss: 8.7885 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 38/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7843 - accuracy: 0.5730 - val_loss: 8.7734 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 39/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7395 - accuracy: 0.6292 - val_loss: 8.7721 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 40/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7840 - accuracy: 0.5169 - val_loss: 8.7696 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 41/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7609 - accuracy: 0.5955 - val_loss: 8.7863 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 42/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7806 - accuracy: 0.5393\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7806 - accuracy: 0.5393 - val_loss: 8.7737 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 43/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7761 - accuracy: 0.5208 - val_loss: 8.7881 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 44/90\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 8.7853 - accuracy: 0.5281 - val_loss: 8.7762 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 45/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7763 - accuracy: 0.5281 - val_loss: 8.7799 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 46/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7590 - accuracy: 0.5730 - val_loss: 8.7547 - val_accuracy: 0.6875 - lr: 1.0000e-07\n",
            "Epoch 47/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7748 - accuracy: 0.5618 - val_loss: 8.7733 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 48/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.8020 - accuracy: 0.5169 - val_loss: 8.7860 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 49/90\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 8.7528 - accuracy: 0.5730 - val_loss: 8.7781 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 50/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7666 - accuracy: 0.5729 - val_loss: 8.7911 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 51/90\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 8.8007 - accuracy: 0.5169 - val_loss: 8.7708 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 52/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7477 - accuracy: 0.6067 - val_loss: 8.7648 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 53/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7969 - accuracy: 0.5056 - val_loss: 8.7823 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 54/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7901 - accuracy: 0.5843 - val_loss: 8.7627 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 55/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7572 - accuracy: 0.5506 - val_loss: 8.7868 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 56/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7926 - accuracy: 0.5281\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7926 - accuracy: 0.5281 - val_loss: 8.7629 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 57/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7795 - accuracy: 0.5521 - val_loss: 8.7889 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 58/90\n",
            "6/6 [==============================] - 1s 208ms/step - loss: 8.7558 - accuracy: 0.6292 - val_loss: 8.7717 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 59/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7516 - accuracy: 0.5618 - val_loss: 8.7697 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 60/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.7751 - accuracy: 0.5955 - val_loss: 8.7961 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 61/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7621 - accuracy: 0.5730 - val_loss: 8.7881 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 62/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7452 - accuracy: 0.5843 - val_loss: 8.7733 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 63/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7303 - accuracy: 0.6966 - val_loss: 8.7725 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 64/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7621 - accuracy: 0.6042 - val_loss: 8.7720 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 65/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7402 - accuracy: 0.7079 - val_loss: 8.7779 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 66/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8041 - accuracy: 0.5730\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.8041 - accuracy: 0.5730 - val_loss: 8.7718 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 67/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.7674 - accuracy: 0.5843 - val_loss: 8.7640 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 68/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7455 - accuracy: 0.6404 - val_loss: 8.7729 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 69/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.7799 - accuracy: 0.5506 - val_loss: 8.7804 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 70/90\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 8.7532 - accuracy: 0.6067 - val_loss: 8.7713 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 71/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7781 - accuracy: 0.5417 - val_loss: 8.7710 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 72/90\n",
            "6/6 [==============================] - 1s 208ms/step - loss: 8.7618 - accuracy: 0.6067 - val_loss: 8.8055 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 73/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7990 - accuracy: 0.5730 - val_loss: 8.7641 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 74/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.7424 - accuracy: 0.6067 - val_loss: 8.7887 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 75/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7432 - accuracy: 0.6292 - val_loss: 8.7605 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 76/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8069 - accuracy: 0.4494\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8069 - accuracy: 0.4494 - val_loss: 8.7692 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 77/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.7697 - accuracy: 0.5843 - val_loss: 8.7825 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 78/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7845 - accuracy: 0.5625 - val_loss: 8.7694 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 79/90\n",
            "6/6 [==============================] - 1s 219ms/step - loss: 8.7528 - accuracy: 0.5843 - val_loss: 8.7658 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 80/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.7625 - accuracy: 0.5393 - val_loss: 8.7884 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 81/90\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.7795 - accuracy: 0.4831 - val_loss: 8.7810 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 82/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.7448 - accuracy: 0.6292 - val_loss: 8.7807 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 83/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7774 - accuracy: 0.5393 - val_loss: 8.7700 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 84/90\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 8.7481 - accuracy: 0.6629 - val_loss: 8.7802 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 85/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7999 - accuracy: 0.5208 - val_loss: 8.7813 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 86/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7591 - accuracy: 0.5618\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 215ms/step - loss: 8.7591 - accuracy: 0.5618 - val_loss: 8.7851 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 87/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.7612 - accuracy: 0.5506 - val_loss: 8.7790 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 88/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7818 - accuracy: 0.5393 - val_loss: 8.7765 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 89/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7791 - accuracy: 0.5730 - val_loss: 8.7721 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 90/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7503 - accuracy: 0.6180 - val_loss: 8.7724 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            " ======== InceptionV3 ======== \n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Found 23 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/90\n",
            "6/6 [==============================] - 3s 462ms/step - loss: 9.0796 - accuracy: 0.4479 - val_loss: 8.9158 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 9.1105 - accuracy: 0.3820 - val_loss: 8.9024 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.9359 - accuracy: 0.4157 - val_loss: 8.8387 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.9467 - accuracy: 0.4719 - val_loss: 8.8597 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.9360 - accuracy: 0.4607 - val_loss: 8.9060 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.9274 - accuracy: 0.4157 - val_loss: 8.7681 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.8960 - accuracy: 0.3933 - val_loss: 8.8175 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 8.8666 - accuracy: 0.5208 - val_loss: 8.8439 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.8503 - accuracy: 0.5056 - val_loss: 8.8040 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.8908 - accuracy: 0.4382 - val_loss: 8.8707 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.8363 - accuracy: 0.4944 - val_loss: 8.8307 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8450 - accuracy: 0.4382 - val_loss: 8.8512 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.8338 - accuracy: 0.4607 - val_loss: 8.8469 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.8256 - accuracy: 0.4494 - val_loss: 8.8315 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "6/6 [==============================] - 1s 208ms/step - loss: 8.8456 - accuracy: 0.4271 - val_loss: 8.8431 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8348 - accuracy: 0.4607\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 8.8348 - accuracy: 0.4607 - val_loss: 8.8160 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 17/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.8377 - accuracy: 0.5169 - val_loss: 8.8406 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 18/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.8202 - accuracy: 0.5730 - val_loss: 8.8408 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 19/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.8137 - accuracy: 0.4831 - val_loss: 8.8714 - val_accuracy: 0.1250 - lr: 1.0000e-05\n",
            "Epoch 20/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.8013 - accuracy: 0.5169 - val_loss: 8.8122 - val_accuracy: 0.2500 - lr: 1.0000e-05\n",
            "Epoch 21/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8048 - accuracy: 0.5618 - val_loss: 8.8373 - val_accuracy: 0.2500 - lr: 1.0000e-05\n",
            "Epoch 22/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.8172 - accuracy: 0.5417 - val_loss: 8.7653 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 23/90\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 8.8118 - accuracy: 0.5506 - val_loss: 8.7908 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 24/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.8268 - accuracy: 0.4719 - val_loss: 8.8186 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 25/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.8115 - accuracy: 0.4831 - val_loss: 8.7601 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 26/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7968 - accuracy: 0.5281 - val_loss: 8.7697 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 27/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.8031 - accuracy: 0.5618 - val_loss: 8.7261 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
            "Epoch 28/90\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 8.8758 - accuracy: 0.4157 - val_loss: 8.7997 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 29/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.8914 - accuracy: 0.3646 - val_loss: 8.7554 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 30/90\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 8.8410 - accuracy: 0.4944 - val_loss: 8.7622 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 31/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.8532 - accuracy: 0.4831 - val_loss: 8.7567 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 32/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.8510 - accuracy: 0.4607 - val_loss: 8.7852 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 33/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.8529 - accuracy: 0.5169 - val_loss: 8.8018 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 34/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.8239 - accuracy: 0.4719 - val_loss: 8.7950 - val_accuracy: 0.3125 - lr: 1.0000e-05\n",
            "Epoch 35/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.8509 - accuracy: 0.4494 - val_loss: 8.8044 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 36/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.8508 - accuracy: 0.4167 - val_loss: 8.8241 - val_accuracy: 0.3750 - lr: 1.0000e-05\n",
            "Epoch 37/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8299 - accuracy: 0.5169\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "6/6 [==============================] - 1s 224ms/step - loss: 8.8299 - accuracy: 0.5169 - val_loss: 8.7782 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 38/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7727 - accuracy: 0.5955 - val_loss: 8.7739 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 39/90\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.8729 - accuracy: 0.4494 - val_loss: 8.8086 - val_accuracy: 0.3125 - lr: 1.0000e-06\n",
            "Epoch 40/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.7926 - accuracy: 0.4831 - val_loss: 8.8001 - val_accuracy: 0.3750 - lr: 1.0000e-06\n",
            "Epoch 41/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.8005 - accuracy: 0.5169 - val_loss: 8.8004 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 42/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8578 - accuracy: 0.4494 - val_loss: 8.8033 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 43/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.8088 - accuracy: 0.5312 - val_loss: 8.8133 - val_accuracy: 0.3750 - lr: 1.0000e-06\n",
            "Epoch 44/90\n",
            "6/6 [==============================] - 1s 209ms/step - loss: 8.8727 - accuracy: 0.4494 - val_loss: 8.7746 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 45/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8223 - accuracy: 0.5169 - val_loss: 8.7983 - val_accuracy: 0.3125 - lr: 1.0000e-06\n",
            "Epoch 46/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.8485 - accuracy: 0.4494 - val_loss: 8.7760 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 47/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8364 - accuracy: 0.4719\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.8364 - accuracy: 0.4719 - val_loss: 8.7516 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 48/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8361 - accuracy: 0.4494 - val_loss: 8.7570 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 49/90\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 8.8472 - accuracy: 0.4270 - val_loss: 8.8139 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 50/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7998 - accuracy: 0.5833 - val_loss: 8.7860 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 51/90\n",
            "6/6 [==============================] - 1s 209ms/step - loss: 8.8415 - accuracy: 0.4944 - val_loss: 8.7898 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 52/90\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 8.8507 - accuracy: 0.4382 - val_loss: 8.8361 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 53/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.8411 - accuracy: 0.4719 - val_loss: 8.7856 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 54/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.8054 - accuracy: 0.5169 - val_loss: 8.7945 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 55/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.8823 - accuracy: 0.3258 - val_loss: 8.7898 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 56/90\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.8253 - accuracy: 0.4494 - val_loss: 8.7870 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 57/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8129 - accuracy: 0.5104\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.8129 - accuracy: 0.5104 - val_loss: 8.7951 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 58/90\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 8.7938 - accuracy: 0.5618 - val_loss: 8.7998 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 59/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.8367 - accuracy: 0.4494 - val_loss: 8.8337 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 60/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7682 - accuracy: 0.5281 - val_loss: 8.8016 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 61/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.8227 - accuracy: 0.4719 - val_loss: 8.8063 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 62/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7919 - accuracy: 0.4944 - val_loss: 8.7985 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 63/90\n",
            "6/6 [==============================] - 1s 190ms/step - loss: 8.8325 - accuracy: 0.4607 - val_loss: 8.8014 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 64/90\n",
            "6/6 [==============================] - 1s 209ms/step - loss: 8.8048 - accuracy: 0.5104 - val_loss: 8.7696 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 65/90\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 8.8938 - accuracy: 0.4157 - val_loss: 8.7764 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 66/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7890 - accuracy: 0.4944 - val_loss: 8.8134 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 67/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8132 - accuracy: 0.5393\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.8132 - accuracy: 0.5393 - val_loss: 8.7920 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 68/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.8075 - accuracy: 0.5281 - val_loss: 8.8127 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 69/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.8307 - accuracy: 0.4607 - val_loss: 8.8083 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 70/90\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 8.8574 - accuracy: 0.4944 - val_loss: 8.8291 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 71/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.8531 - accuracy: 0.4375 - val_loss: 8.8230 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 72/90\n",
            "6/6 [==============================] - 1s 221ms/step - loss: 8.8490 - accuracy: 0.4944 - val_loss: 8.8203 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 73/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.8482 - accuracy: 0.4719 - val_loss: 8.8169 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 74/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.8720 - accuracy: 0.4045 - val_loss: 8.7958 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 75/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.8109 - accuracy: 0.5056 - val_loss: 8.7969 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 76/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.8257 - accuracy: 0.4944 - val_loss: 8.7615 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 77/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8166 - accuracy: 0.5281\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.8166 - accuracy: 0.5281 - val_loss: 8.7898 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 78/90\n",
            "6/6 [==============================] - 1s 208ms/step - loss: 8.7892 - accuracy: 0.5521 - val_loss: 8.8052 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 79/90\n",
            "6/6 [==============================] - 1s 224ms/step - loss: 8.8012 - accuracy: 0.5281 - val_loss: 8.7763 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 80/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.8184 - accuracy: 0.4944 - val_loss: 8.7993 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 81/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7747 - accuracy: 0.5506 - val_loss: 8.7979 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 82/90\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 8.8238 - accuracy: 0.4719 - val_loss: 8.8339 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 83/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.8088 - accuracy: 0.5281 - val_loss: 8.8202 - val_accuracy: 0.3125 - lr: 1.0000e-07\n",
            "Epoch 84/90\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 8.7870 - accuracy: 0.5281 - val_loss: 8.7985 - val_accuracy: 0.3750 - lr: 1.0000e-07\n",
            "Epoch 85/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.8348 - accuracy: 0.4688 - val_loss: 8.8245 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 86/90\n",
            "6/6 [==============================] - 1s 242ms/step - loss: 8.8344 - accuracy: 0.4719 - val_loss: 8.7972 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 87/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.8138 - accuracy: 0.4944\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 222ms/step - loss: 8.8138 - accuracy: 0.4944 - val_loss: 8.8128 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 88/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.8302 - accuracy: 0.4831 - val_loss: 8.7979 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 89/90\n",
            "6/6 [==============================] - 1s 192ms/step - loss: 8.8430 - accuracy: 0.4719 - val_loss: 8.7540 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 90/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.9060 - accuracy: 0.3820 - val_loss: 8.8154 - val_accuracy: 0.3750 - lr: 1.0000e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcM-J2XNom2w",
        "colab_type": "text"
      },
      "source": [
        "### Finetune 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJB9oVcDRnLm",
        "colab_type": "code",
        "outputId": "3ba14eae-8951-4134-bd92-cc4f0264e449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hyperparameters = {\n",
        "    'img_size': 224,\n",
        "    'num_classes': 2,\n",
        "    'base': 'InceptionV3',\n",
        "    'finetune_blocks': 2,\n",
        "    'base_lr': 0.0001,\n",
        "    'epochs': 90,\n",
        "    'batch_size': 16,\n",
        "    'dataset': 'MIAS'\n",
        "}\n",
        "\n",
        "print(' ======== VGG16 ======== ')\n",
        "hyperparameters['base'] = 'VGG16'\n",
        "hist_vgg_2 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== ResNet50 ======== ')\n",
        "hyperparameters['base'] = 'ResNet50'\n",
        "hist_r50_2 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== InceptionV3 ======== ')\n",
        "hyperparameters['base'] = 'InceptionV3'\n",
        "hist_iv3_2 = train_model(hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ======== VGG16 ======== \n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Found 23 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"dstpath\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"dstpath\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "6/6 [==============================] - 2s 254ms/step - loss: 8.8666 - accuracy: 0.4167 - val_loss: 8.7708 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 8.8017 - accuracy: 0.4719 - val_loss: 8.7533 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7797 - accuracy: 0.4607 - val_loss: 8.7527 - val_accuracy: 0.3125 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7882 - accuracy: 0.3933 - val_loss: 8.7511 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7310 - accuracy: 0.5393 - val_loss: 8.7336 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7412 - accuracy: 0.4944 - val_loss: 8.7625 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7185 - accuracy: 0.5281 - val_loss: 8.7642 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7255 - accuracy: 0.5729 - val_loss: 8.7465 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7604 - accuracy: 0.4719 - val_loss: 8.8019 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7577 - accuracy: 0.4831 - val_loss: 8.7501 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7543 - accuracy: 0.5169 - val_loss: 8.7198 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7423 - accuracy: 0.5506 - val_loss: 8.7804 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7427 - accuracy: 0.5618 - val_loss: 8.7741 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7668 - accuracy: 0.5169 - val_loss: 8.7190 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 8.7321 - accuracy: 0.5729 - val_loss: 8.7483 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "6/6 [==============================] - 1s 219ms/step - loss: 8.7396 - accuracy: 0.4944 - val_loss: 8.7168 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 17/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7658 - accuracy: 0.4607 - val_loss: 8.7772 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 18/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7295 - accuracy: 0.5618 - val_loss: 8.7462 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 19/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7438 - accuracy: 0.5843 - val_loss: 8.7845 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 20/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7488 - accuracy: 0.5506 - val_loss: 8.7690 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 21/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7035 - accuracy: 0.6517 - val_loss: 8.7749 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 22/90\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 8.7072 - accuracy: 0.5729 - val_loss: 8.7455 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 23/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7174 - accuracy: 0.5281 - val_loss: 8.7136 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 24/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7185 - accuracy: 0.5506 - val_loss: 8.7856 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 25/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7343 - accuracy: 0.5730 - val_loss: 8.8175 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 26/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7175 - accuracy: 0.5843 - val_loss: 8.7882 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 27/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7305 - accuracy: 0.5393 - val_loss: 8.8547 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
            "Epoch 28/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7304 - accuracy: 0.6180 - val_loss: 8.7568 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 29/90\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 8.7274 - accuracy: 0.5417 - val_loss: 8.8141 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 30/90\n",
            "6/6 [==============================] - 1s 215ms/step - loss: 8.7417 - accuracy: 0.5618 - val_loss: 8.8149 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 31/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7105 - accuracy: 0.5506 - val_loss: 8.7473 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 32/90\n",
            "6/6 [==============================] - 1s 199ms/step - loss: 8.7201 - accuracy: 0.5955 - val_loss: 8.7834 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 33/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7289 - accuracy: 0.5955\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7289 - accuracy: 0.5955 - val_loss: 8.8235 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 34/90\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 8.7280 - accuracy: 0.5506 - val_loss: 8.7796 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 35/90\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 8.7463 - accuracy: 0.5506 - val_loss: 8.7891 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 36/90\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 8.7199 - accuracy: 0.6042 - val_loss: 8.7511 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 37/90\n",
            "6/6 [==============================] - 1s 215ms/step - loss: 8.7348 - accuracy: 0.4944 - val_loss: 8.8143 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 38/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7024 - accuracy: 0.6404 - val_loss: 8.7117 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 39/90\n",
            "6/6 [==============================] - 1s 198ms/step - loss: 8.7227 - accuracy: 0.5506 - val_loss: 8.7414 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 40/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7468 - accuracy: 0.5056 - val_loss: 8.7855 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 41/90\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 8.7343 - accuracy: 0.5281 - val_loss: 8.7445 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 42/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7114 - accuracy: 0.6404 - val_loss: 8.7858 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 43/90\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 8.7507 - accuracy: 0.5729 - val_loss: 8.7843 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 44/90\n",
            "6/6 [==============================] - 1s 224ms/step - loss: 8.7208 - accuracy: 0.5618 - val_loss: 8.7530 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
            "Epoch 45/90\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 8.7404 - accuracy: 0.5281 - val_loss: 8.7118 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 46/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7354 - accuracy: 0.5281 - val_loss: 8.7818 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 47/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.7471 - accuracy: 0.5393 - val_loss: 8.7765 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 48/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7513 - accuracy: 0.6067\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7513 - accuracy: 0.6067 - val_loss: 8.8139 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
            "Epoch 49/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7032 - accuracy: 0.6180 - val_loss: 8.7444 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 50/90\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 8.7098 - accuracy: 0.5938 - val_loss: 8.7773 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 51/90\n",
            "6/6 [==============================] - 1s 221ms/step - loss: 8.7302 - accuracy: 0.5281 - val_loss: 8.8150 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 52/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.6994 - accuracy: 0.5618 - val_loss: 8.8165 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
            "Epoch 53/90\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 8.7086 - accuracy: 0.5730 - val_loss: 8.7822 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 54/90\n",
            "6/6 [==============================] - 1s 203ms/step - loss: 8.7225 - accuracy: 0.5506 - val_loss: 8.7495 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 55/90\n",
            "6/6 [==============================] - 3s 467ms/step - loss: 8.7445 - accuracy: 0.4831 - val_loss: 8.7181 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 56/90\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 8.6957 - accuracy: 0.6629 - val_loss: 8.7476 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 57/90\n",
            "6/6 [==============================] - 1s 205ms/step - loss: 8.7480 - accuracy: 0.5521 - val_loss: 8.7443 - val_accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 58/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7477 - accuracy: 0.5393\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "6/6 [==============================] - 1s 220ms/step - loss: 8.7477 - accuracy: 0.5393 - val_loss: 8.7767 - val_accuracy: 0.5000 - lr: 1.0000e-06\n",
            "Epoch 59/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7191 - accuracy: 0.5506 - val_loss: 8.8177 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 60/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7391 - accuracy: 0.5730 - val_loss: 8.7481 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 61/90\n",
            "6/6 [==============================] - 1s 202ms/step - loss: 8.7396 - accuracy: 0.5843 - val_loss: 8.7795 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 62/90\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 8.7529 - accuracy: 0.5730 - val_loss: 8.7498 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 63/90\n",
            "6/6 [==============================] - 1s 194ms/step - loss: 8.7206 - accuracy: 0.5955 - val_loss: 8.7495 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 64/90\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 8.6998 - accuracy: 0.6042 - val_loss: 8.7152 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 65/90\n",
            "6/6 [==============================] - 1s 230ms/step - loss: 8.7695 - accuracy: 0.5169 - val_loss: 8.7443 - val_accuracy: 0.5625 - lr: 1.0000e-07\n",
            "Epoch 66/90\n",
            "6/6 [==============================] - 1s 221ms/step - loss: 8.7563 - accuracy: 0.5393 - val_loss: 8.7807 - val_accuracy: 0.5000 - lr: 1.0000e-07\n",
            "Epoch 67/90\n",
            "6/6 [==============================] - 1s 216ms/step - loss: 8.7310 - accuracy: 0.5393 - val_loss: 8.7081 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Epoch 68/90\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.7206 - accuracy: 0.5955 - val_loss: 8.8153 - val_accuracy: 0.4375 - lr: 1.0000e-07\n",
            "Epoch 69/90\n",
            "6/6 [==============================] - ETA: 0s - loss: 8.7681 - accuracy: 0.5169"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-WKxtsYootx",
        "colab_type": "text"
      },
      "source": [
        "### Finetune 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvxn_eenRnuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameters = {\n",
        "    'img_size': 224,\n",
        "    'num_classes': 2,\n",
        "    'base': 'InceptionV3',\n",
        "    'finetune_blocks': 3,\n",
        "    'base_lr': 0.0001,\n",
        "    'epochs': 90,\n",
        "    'batch_size': 16,\n",
        "    'dataset': 'MIAS'\n",
        "}\n",
        "\n",
        "print(' ======== VGG16 ======== ')\n",
        "hyperparameters['base'] = 'VGG16'\n",
        "hist_vgg_3 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== ResNet50 ======== ')\n",
        "hyperparameters['base'] = 'ResNet50'\n",
        "hist_r50_3 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== InceptionV3 ======== ')\n",
        "hyperparameters['base'] = 'InceptionV3'\n",
        "hist_iv3_3 = train_model(hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTPV8Bh0orIh",
        "colab_type": "text"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpU5_t6Zos2y",
        "colab_type": "text"
      },
      "source": [
        "                0           1           2           3\n",
        "VGG16          50           57         50          71           \n",
        "ResNet50       50           57         50          57\n",
        "InceptionV3    57           64         43          64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpnlw_5qouS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('======== VGG 16 : 0 Finetuning ========')\n",
        "plot(hist_vgg_0)\n",
        "print('======== VGG 16 : 1 Finetuning ========')\n",
        "plot(hist_vgg_1)\n",
        "print('======== VGG 16 : 2 Finetuning ========')\n",
        "plot(hist_vgg_2)\n",
        "print('======== VGG 16 : 3 Finetuning ========')\n",
        "plot(hist_vgg_3)\n",
        "\n",
        "print('======== ResNet50 : 0 Finetuning ========')\n",
        "plot(hist_r50_0)\n",
        "print('======== ResNet50 : 1 Finetuning ========')\n",
        "plot(hist_r50_1)\n",
        "print('======== ResNet50 : 2 Finetuning ========')\n",
        "plot(hist_r50_2)\n",
        "print('======== ResNet50 : 3 Finetuning ========')\n",
        "plot(hist_r50_3)\n",
        "\n",
        "print('======== InceptionV3 : 0 Finetuning ========')\n",
        "plot(hist_iv3_0)\n",
        "print('======== InceptionV3 : 1 Finetuning ========')\n",
        "plot(hist_iv3_1)\n",
        "print('======== InceptionV3 : 2 Finetuning ========')\n",
        "plot(hist_iv3_2)\n",
        "print('======== InceptionV3 : 3 Finetuning ========')\n",
        "plot(hist_iv3_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iZQ6oQ6otc7",
        "colab_type": "text"
      },
      "source": [
        "## TRAIN INBREAST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r86wyigbovjv",
        "colab_type": "text"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "041hz2GUDTRy",
        "colab_type": "code",
        "outputId": "b58ebab2-2aea-4e9b-ff9e-108c6b97d5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cropped_dir = '/content/data/INbreast/cropped/'\n",
        "if not os.path.isdir(cropped_dir):\n",
        "  os.makedirs(cropped_dir)\n",
        "\n",
        "img_paths = {}\n",
        "img_root = '/content/data/INbreast/images/'\n",
        "for file in os.listdir(img_root):\n",
        "    img_paths[int(file.split('_')[0])] = img_root + file\n",
        "\n",
        "df_labels = pd.read_csv('/content/data/INbreast/labels.csv')\n",
        "df_annotations = pd.read_csv('/content/data/INbreast/annotations.csv')\n",
        "df_annotations['dx'] = [row.xmax - row.xmin for row in df_annotations.itertuples()]\n",
        "df_annotations['dy'] = [row.ymax - row.ymin for row in df_annotations.itertuples()]\n",
        "df_annotations = df_annotations[df_annotations.dx > 10][df_annotations.dy > 10]\n",
        "df_annotations['yc'] = [int((row.ymax + row.ymin)/2) for row in df_annotations.itertuples()]\n",
        "df_annotations['xc'] = [int((row.xmax + row.xmin)/2) for row in df_annotations.itertuples()]\n",
        "df_annotations['cancer'] = [int(int(df_labels[df_labels['File Name'] == row.fileid]['Bi-Rads'].iloc[0][0]) > 3) for row in df_annotations.itertuples()]\n",
        "df_annotations['filepath'] = [cropped_dir + str(fileid) + '.jpg' for fileid in df_annotations.fileid.to_list()]\n",
        "df_annotations['ogpath'] = [img_paths[fileid] for fileid in df_annotations.fileid.to_list()]\n",
        "df_annotations = df_annotations.sample(frac=1).reset_index(drop=True)\n",
        "img_shapes = {}\n",
        "for row in df_annotations.itertuples():\n",
        "  img_shapes[row.fileid] = Image.open(row.ogpath).size\n",
        "df_annotations['W'] = [img_shapes[fid][0] for fid in df_annotations.fileid.to_list()]\n",
        "df_annotations['H'] = [img_shapes[fid][1] for fid in df_annotations.fileid.to_list()]\n",
        "df_annotations = df_annotations[df_annotations.ymax < df_annotations.H]\n",
        "df_annotations.to_csv('/content/data/INbreast/annotations0.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1R6bsSUpG9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_annotations = pd.read_csv('/content/data/INbreast/annotations0.csv')\n",
        "for row in df_annotations.itertuples():\n",
        "    img = cv2.imread(row.ogpath)\n",
        "    height, width = img.shape[:2]\n",
        "    xc, yc = row.xc, row.yc\n",
        "    xmin = max(xc - (224/2), 0)\n",
        "    xmax = min(xc + (224/2), width)\n",
        "    xmin += (224/2) - (xmax-xc)\n",
        "    xmax += (224/2) - (xc - xmin)\n",
        "    ymin = max(yc - (224/2), 0)\n",
        "    ymax = min(yc + (224/2), height)\n",
        "    ymin += (224/2) - (ymax-yc)\n",
        "    ymax += (224/2) - (yc - ymin)\n",
        "    xmin, xmax, ymin, ymax = int(xmin), int(xmax), int(ymin), int(ymax)\n",
        "    # img = img[row.xmin:row.xmax, row.ymin:row.ymax]\n",
        "    img = img[ymin:ymax, xmin:xmax]\n",
        "    cv2.imwrite(row.filepath, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLlbj3F8oyMz",
        "colab_type": "text"
      },
      "source": [
        "### Finetune 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig_xrSFd7tEQ",
        "colab_type": "code",
        "outputId": "f4d61f94-506e-48d5-f6ae-420a7dcac088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "hyperparameters = {\n",
        "    'img_size': 224,\n",
        "    'num_classes': 2,\n",
        "    'base': 'InceptionV3',\n",
        "    'finetune_blocks': 0,\n",
        "    'base_lr': 0.0001,\n",
        "    'epochs': 90,\n",
        "    'batch_size': 16,\n",
        "    'dataset': 'INbreast'\n",
        "}\n",
        "\n",
        "print(' ======== VGG16 ======== ')\n",
        "hyperparameters['base'] = 'VGG16'\n",
        "hist_vgg_0 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== ResNet50 ======== ')\n",
        "hyperparameters['base'] = 'ResNet50'\n",
        "hist_r50_0 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== InceptionV3 ======== ')\n",
        "hyperparameters['base'] = 'InceptionV3'\n",
        "hist_iv3_0 = train_model(hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ======== VGG16 ======== \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'cancer'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-64a4c371dabc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ======== VGG16 ======== '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'VGG16'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhist_vgg_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ======== ResNet50 ======== '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6930fdbe7526>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    165\u001b[0m                                     \u001b[0mycol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                                     batch_size)\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6930fdbe7526>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(train_df, valid_df, xcol, ycol, img_size, batch_size)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         class_mode = 'categorical')\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     valid_generator = validation_datagen.flow_from_dataframe(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_valid_filepaths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_mode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multi_output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# build an index of all the unique classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m_filter_classes\u001b[0;34m(df, y_col, classes)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'cancer'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU0IOYXVo0L_",
        "colab_type": "text"
      },
      "source": [
        "### Finetune 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoOMbjkx8W8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameters = {\n",
        "    'img_size': 224,\n",
        "    'num_classes': 2,\n",
        "    'base': 'InceptionV3',\n",
        "    'finetune_blocks': 1,\n",
        "    'base_lr': 0.0001,\n",
        "    'epochs': 90,\n",
        "    'batch_size': 16,\n",
        "    'dataset': 'MIAS'\n",
        "}\n",
        "\n",
        "print(' ======== VGG16 ======== ')\n",
        "hyperparameters['base'] = 'VGG16'\n",
        "hist_vgg_1 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== ResNet50 ======== ')\n",
        "hyperparameters['base'] = 'ResNet50'\n",
        "hist_r50_1 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== InceptionV3 ======== ')\n",
        "hyperparameters['base'] = 'InceptionV3'\n",
        "hist_iv3_1 = train_model(hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-nDK8HBo1Lb",
        "colab_type": "text"
      },
      "source": [
        "### Finetune 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-6iwYBE8bxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameters = {\n",
        "    'img_size': 224,\n",
        "    'num_classes': 2,\n",
        "    'base': 'InceptionV3',\n",
        "    'finetune_blocks': 2,\n",
        "    'base_lr': 0.0001,\n",
        "    'epochs': 90,\n",
        "    'batch_size': 16,\n",
        "    'dataset': 'MIAS'\n",
        "}\n",
        "\n",
        "print(' ======== VGG16 ======== ')\n",
        "hyperparameters['base'] = 'VGG16'\n",
        "hist_vgg_2 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== ResNet50 ======== ')\n",
        "hyperparameters['base'] = 'ResNet50'\n",
        "hist_r50_2 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== InceptionV3 ======== ')\n",
        "hyperparameters['base'] = 'InceptionV3'\n",
        "hist_iv3_2 = train_model(hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9k_Rx7zo2Gd",
        "colab_type": "text"
      },
      "source": [
        "### Finetune 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEY_7Vs98ek8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameters = {\n",
        "    'img_size': 224,\n",
        "    'num_classes': 2,\n",
        "    'base': 'InceptionV3',\n",
        "    'finetune_blocks': 3,\n",
        "    'base_lr': 0.0001,\n",
        "    'epochs': 90,\n",
        "    'batch_size': 16,\n",
        "    'dataset': 'MIAS'\n",
        "}\n",
        "\n",
        "print(' ======== VGG16 ======== ')\n",
        "hyperparameters['base'] = 'VGG16'\n",
        "hist_vgg_3 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== ResNet50 ======== ')\n",
        "hyperparameters['base'] = 'ResNet50'\n",
        "hist_r50_3 = train_model(hyperparameters)\n",
        "\n",
        "print(' ======== InceptionV3 ======== ')\n",
        "hyperparameters['base'] = 'InceptionV3'\n",
        "hist_iv3_3 = train_model(hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss4Ipm28o3La",
        "colab_type": "text"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhFIXKkl8ghA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('======== VGG 16 : 0 Finetuning ========')\n",
        "plot(hist_vgg_0)\n",
        "print('======== VGG 16 : 1 Finetuning ========')\n",
        "plot(hist_vgg_1)\n",
        "print('======== VGG 16 : 2 Finetuning ========')\n",
        "plot(hist_vgg_2)\n",
        "print('======== VGG 16 : 3 Finetuning ========')\n",
        "plot(hist_vgg_3)\n",
        "\n",
        "print('======== ResNet50 : 0 Finetuning ========')\n",
        "plot(hist_r50_0)\n",
        "print('======== ResNet50 : 1 Finetuning ========')\n",
        "plot(hist_r50_1)\n",
        "print('======== ResNet50 : 2 Finetuning ========')\n",
        "plot(hist_r50_2)\n",
        "print('======== ResNet50 : 3 Finetuning ========')\n",
        "plot(hist_r50_3)\n",
        "\n",
        "print('======== InceptionV3 : 0 Finetuning ========')\n",
        "plot(hist_iv3_0)\n",
        "print('======== InceptionV3 : 1 Finetuning ========')\n",
        "plot(hist_iv3_1)\n",
        "print('======== InceptionV3 : 2 Finetuning ========')\n",
        "plot(hist_iv3_2)\n",
        "print('======== InceptionV3 : 3 Finetuning ========')\n",
        "plot(hist_iv3_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK5jBlERKbgs",
        "colab_type": "text"
      },
      "source": [
        "## Attempt at installing and compiling py-faster-rcnn and caffe\n",
        "\n",
        "Note that the Makefiles at each stage have to be tweaked depending on the environment. Good luck with that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z5jlezAE-YD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72fc3fbe-1197-47e8-f1e6-f816bcd6bb93"
      },
      "source": [
        "!apt install caffe-cuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  caffe-tools-cuda cython3 fonts-lyx javascript-common libblosc1\n",
            "  libcaffe-cuda1 libcublas9.1 libcudart9.1 libcurand9.1 libgflags2.2\n",
            "  libgoogle-glog0v5 libjs-jquery libjs-jquery-ui libleveldb1v5 liblmdb0\n",
            "  python-matplotlib-data python-tables-data python3-bs4 python3-caffe-cuda\n",
            "  python3-chardet python3-cycler python3-dateutil python3-decorator\n",
            "  python3-gflags python3-h5py python3-html5lib python3-ipython\n",
            "  python3-ipython-genutils python3-leveldb python3-lxml python3-matplotlib\n",
            "  python3-networkx python3-nose python3-numexpr python3-olefile python3-pandas\n",
            "  python3-pandas-lib python3-pexpect python3-pickleshare python3-pil\n",
            "  python3-pkg-resources python3-prompt-toolkit python3-protobuf\n",
            "  python3-ptyprocess python3-pygments python3-pyparsing python3-pywt\n",
            "  python3-scipy python3-simplegeneric python3-six python3-skimage\n",
            "  python3-skimage-lib python3-tables python3-tables-lib python3-traitlets\n",
            "  python3-tz python3-wcwidth python3-webencodings python3-yaml\n",
            "  ttf-bitstream-vera\n",
            "Suggested packages:\n",
            "  libcaffe-cuda-dev caffe-doc cython-doc apache2 | lighttpd | httpd\n",
            "  libjs-jquery-ui-docs python-cycler-doc python-h5py-doc python3-genshi\n",
            "  python3-lxml-dbg python-lxml-doc dvipng gir1.2-gtk-3.0 ghostscript inkscape\n",
            "  ipython3 python-matplotlib-doc python3-cairocffi python3-gi-cairo\n",
            "  python3-gobject python3-pyqt4 python3-sip python3-tornado\n",
            "  texlive-extra-utils texlive-latex-extra ttf-staypuft python3-pydotplus\n",
            "  python-nose-doc python-pandas-doc python-pexpect-doc python-pil-doc\n",
            "  python3-pil-dbg python3-setuptools python-pyparsing-doc python-scipy-doc\n",
            "  python-skimage-doc python-tables-doc python3-netcdf4 vitables\n",
            "The following NEW packages will be installed:\n",
            "  caffe-cuda caffe-tools-cuda cython3 fonts-lyx javascript-common libblosc1\n",
            "  libcaffe-cuda1 libcublas9.1 libcudart9.1 libcurand9.1 libgflags2.2\n",
            "  libgoogle-glog0v5 libjs-jquery libjs-jquery-ui libleveldb1v5 liblmdb0\n",
            "  python-matplotlib-data python-tables-data python3-bs4 python3-caffe-cuda\n",
            "  python3-chardet python3-cycler python3-dateutil python3-decorator\n",
            "  python3-gflags python3-h5py python3-html5lib python3-ipython\n",
            "  python3-ipython-genutils python3-leveldb python3-lxml python3-matplotlib\n",
            "  python3-networkx python3-nose python3-numexpr python3-olefile python3-pandas\n",
            "  python3-pandas-lib python3-pexpect python3-pickleshare python3-pil\n",
            "  python3-pkg-resources python3-prompt-toolkit python3-protobuf\n",
            "  python3-ptyprocess python3-pygments python3-pyparsing python3-pywt\n",
            "  python3-scipy python3-simplegeneric python3-six python3-skimage\n",
            "  python3-skimage-lib python3-tables python3-tables-lib python3-traitlets\n",
            "  python3-tz python3-wcwidth python3-webencodings python3-yaml\n",
            "  ttf-bitstream-vera\n",
            "0 upgraded, 61 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 121 MB of archives.\n",
            "After this operation, 316 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-yaml amd64 3.12-1build2 [109 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcublas9.1 amd64 9.1.85-3ubuntu1 [25.0 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcudart9.1 amd64 9.1.85-3ubuntu1 [121 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcurand9.1 amd64 9.1.85-3ubuntu1 [38.9 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgflags2.2 amd64 2.2.1-1 [72.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgoogle-glog0v5 amd64 0.3.5-1 [50.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libleveldb1v5 amd64 1.20-2 [136 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 liblmdb0 amd64 0.9.21-1ubuntu0.1 [44.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcaffe-cuda1 amd64 1.0.0-6build1 [1,600 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 caffe-tools-cuda amd64 1.0.0-6build1 [105 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cython3 amd64 0.26.1-0.4 [1,925 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-dateutil all 2.6.1-1 [52.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-gflags all 1.5.1-5 [35.6 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-h5py amd64 2.7.1-2 [631 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-decorator all 4.1.2-1 [9,364 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-ptyprocess all 0.5.2-1 [12.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pexpect all 4.2.1-1 [42.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pickleshare all 0.7.4-2 [6,904 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wcwidth all 0.1.7+dfsg1-1 [14.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-prompt-toolkit all 1.0.15-1 [163 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pygments all 2.2.0+dfsg-1 [574 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-simplegeneric all 0.8.1-1 [11.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-ipython-genutils all 0.2.0-1 [20.9 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-traitlets all 4.3.2-1 [59.1 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-ipython all 5.5.0-1 [381 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-leveldb amd64 0~svn68-3build3 [18.3 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 fonts-lyx all 2.2.4-0ubuntu0.18.04.1 [155 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ttf-bitstream-vera all 1.10-8 [352 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-matplotlib-data all 2.1.1-2ubuntu3 [3,774 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pyparsing all 2.2.0+dfsg1-2 [52.2 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-tz all 2018.3-2 [25.1 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjs-jquery-ui all 1.12.1+dfsg-5 [232 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-cycler all 0.10.0-1 [7,622 B]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-matplotlib amd64 2.1.1-2ubuntu3 [3,907 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-networkx all 1.11-1ubuntu3 [606 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-nose all 1.3.7-3 [115 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pandas-lib amd64 0.22.0-4ubuntu1 [3,041 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pandas all 0.22.0-4ubuntu1 [2,765 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-pil amd64 5.1.0-1ubuntu0.2 [329 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-protobuf amd64 3.0.0-9.1ubuntu1 [262 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-scipy amd64 0.19.1-2ubuntu1 [9,619 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-skimage-lib amd64 0.13.1-2 [1,504 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pywt amd64 0.5.1-1.1ubuntu4 [932 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-skimage all 0.13.1-2 [19.6 MB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 python3-caffe-cuda amd64 1.0.0-6build1 [689 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 caffe-cuda amd64 1.0.0-6build1 [4,564 B]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libblosc1 amd64 1.14.2+ds1-1 [31.4 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-tables-data all 3.4.2-4 [46.1 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-bs4 all 4.6.0-1 [67.8 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-webencodings all 0.5-2 [10.4 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-html5lib all 0.999999999-1 [81.9 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-lxml amd64 4.2.1-1ubuntu0.1 [1,091 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-numexpr amd64 2.6.4-1 [119 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-olefile all 0.45.1-1 [33.3 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-tables-lib amd64 3.4.2-4 [413 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-tables all 3.4.2-4 [331 kB]\n",
            "Fetched 121 MB in 15s (8,140 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package python3-yaml.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3-yaml_3.12-1build2_amd64.deb ...\n",
            "Unpacking python3-yaml (3.12-1build2) ...\n",
            "Selecting previously unselected package libcublas9.1:amd64.\n",
            "Preparing to unpack .../01-libcublas9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcudart9.1:amd64.\n",
            "Preparing to unpack .../02-libcudart9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libcurand9.1:amd64.\n",
            "Preparing to unpack .../03-libcurand9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
            "Unpacking libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Selecting previously unselected package libgflags2.2.\n",
            "Preparing to unpack .../04-libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../05-libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "Preparing to unpack .../06-libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../07-liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libcaffe-cuda1:amd64.\n",
            "Preparing to unpack .../08-libcaffe-cuda1_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking libcaffe-cuda1:amd64 (1.0.0-6build1) ...\n",
            "Selecting previously unselected package caffe-tools-cuda.\n",
            "Preparing to unpack .../09-caffe-tools-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking caffe-tools-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package cython3.\n",
            "Preparing to unpack .../10-cython3_0.26.1-0.4_amd64.deb ...\n",
            "Unpacking cython3 (0.26.1-0.4) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../11-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-dateutil.\n",
            "Preparing to unpack .../12-python3-dateutil_2.6.1-1_all.deb ...\n",
            "Unpacking python3-dateutil (2.6.1-1) ...\n",
            "Selecting previously unselected package python3-gflags.\n",
            "Preparing to unpack .../13-python3-gflags_1.5.1-5_all.deb ...\n",
            "Unpacking python3-gflags (1.5.1-5) ...\n",
            "Selecting previously unselected package python3-h5py.\n",
            "Preparing to unpack .../14-python3-h5py_2.7.1-2_amd64.deb ...\n",
            "Unpacking python3-h5py (2.7.1-2) ...\n",
            "Selecting previously unselected package python3-decorator.\n",
            "Preparing to unpack .../15-python3-decorator_4.1.2-1_all.deb ...\n",
            "Unpacking python3-decorator (4.1.2-1) ...\n",
            "Selecting previously unselected package python3-ptyprocess.\n",
            "Preparing to unpack .../16-python3-ptyprocess_0.5.2-1_all.deb ...\n",
            "Unpacking python3-ptyprocess (0.5.2-1) ...\n",
            "Selecting previously unselected package python3-pexpect.\n",
            "Preparing to unpack .../17-python3-pexpect_4.2.1-1_all.deb ...\n",
            "Unpacking python3-pexpect (4.2.1-1) ...\n",
            "Selecting previously unselected package python3-pickleshare.\n",
            "Preparing to unpack .../18-python3-pickleshare_0.7.4-2_all.deb ...\n",
            "Unpacking python3-pickleshare (0.7.4-2) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../19-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wcwidth.\n",
            "Preparing to unpack .../20-python3-wcwidth_0.1.7+dfsg1-1_all.deb ...\n",
            "Unpacking python3-wcwidth (0.1.7+dfsg1-1) ...\n",
            "Selecting previously unselected package python3-prompt-toolkit.\n",
            "Preparing to unpack .../21-python3-prompt-toolkit_1.0.15-1_all.deb ...\n",
            "Unpacking python3-prompt-toolkit (1.0.15-1) ...\n",
            "Selecting previously unselected package python3-pygments.\n",
            "Preparing to unpack .../22-python3-pygments_2.2.0+dfsg-1_all.deb ...\n",
            "Unpacking python3-pygments (2.2.0+dfsg-1) ...\n",
            "Selecting previously unselected package python3-simplegeneric.\n",
            "Preparing to unpack .../23-python3-simplegeneric_0.8.1-1_all.deb ...\n",
            "Unpacking python3-simplegeneric (0.8.1-1) ...\n",
            "Selecting previously unselected package python3-ipython-genutils.\n",
            "Preparing to unpack .../24-python3-ipython-genutils_0.2.0-1_all.deb ...\n",
            "Unpacking python3-ipython-genutils (0.2.0-1) ...\n",
            "Selecting previously unselected package python3-traitlets.\n",
            "Preparing to unpack .../25-python3-traitlets_4.3.2-1_all.deb ...\n",
            "Unpacking python3-traitlets (4.3.2-1) ...\n",
            "Selecting previously unselected package python3-ipython.\n",
            "Preparing to unpack .../26-python3-ipython_5.5.0-1_all.deb ...\n",
            "Unpacking python3-ipython (5.5.0-1) ...\n",
            "Selecting previously unselected package python3-leveldb.\n",
            "Preparing to unpack .../27-python3-leveldb_0~svn68-3build3_amd64.deb ...\n",
            "Unpacking python3-leveldb (0~svn68-3build3) ...\n",
            "Selecting previously unselected package fonts-lyx.\n",
            "Preparing to unpack .../28-fonts-lyx_2.2.4-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking fonts-lyx (2.2.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package ttf-bitstream-vera.\n",
            "Preparing to unpack .../29-ttf-bitstream-vera_1.10-8_all.deb ...\n",
            "Unpacking ttf-bitstream-vera (1.10-8) ...\n",
            "Selecting previously unselected package python-matplotlib-data.\n",
            "Preparing to unpack .../30-python-matplotlib-data_2.1.1-2ubuntu3_all.deb ...\n",
            "Unpacking python-matplotlib-data (2.1.1-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-pyparsing.\n",
            "Preparing to unpack .../31-python3-pyparsing_2.2.0+dfsg1-2_all.deb ...\n",
            "Unpacking python3-pyparsing (2.2.0+dfsg1-2) ...\n",
            "Selecting previously unselected package python3-tz.\n",
            "Preparing to unpack .../32-python3-tz_2018.3-2_all.deb ...\n",
            "Unpacking python3-tz (2018.3-2) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../33-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libjs-jquery-ui.\n",
            "Preparing to unpack .../34-libjs-jquery-ui_1.12.1+dfsg-5_all.deb ...\n",
            "Unpacking libjs-jquery-ui (1.12.1+dfsg-5) ...\n",
            "Selecting previously unselected package python3-cycler.\n",
            "Preparing to unpack .../35-python3-cycler_0.10.0-1_all.deb ...\n",
            "Unpacking python3-cycler (0.10.0-1) ...\n",
            "Selecting previously unselected package python3-matplotlib.\n",
            "Preparing to unpack .../36-python3-matplotlib_2.1.1-2ubuntu3_amd64.deb ...\n",
            "Unpacking python3-matplotlib (2.1.1-2ubuntu3) ...\n",
            "Selecting previously unselected package python3-networkx.\n",
            "Preparing to unpack .../37-python3-networkx_1.11-1ubuntu3_all.deb ...\n",
            "Unpacking python3-networkx (1.11-1ubuntu3) ...\n",
            "Selecting previously unselected package python3-nose.\n",
            "Preparing to unpack .../38-python3-nose_1.3.7-3_all.deb ...\n",
            "Unpacking python3-nose (1.3.7-3) ...\n",
            "Selecting previously unselected package python3-pandas-lib.\n",
            "Preparing to unpack .../39-python3-pandas-lib_0.22.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking python3-pandas-lib (0.22.0-4ubuntu1) ...\n",
            "Selecting previously unselected package python3-pandas.\n",
            "Preparing to unpack .../40-python3-pandas_0.22.0-4ubuntu1_all.deb ...\n",
            "Unpacking python3-pandas (0.22.0-4ubuntu1) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../41-python3-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Selecting previously unselected package python3-protobuf.\n",
            "Preparing to unpack .../42-python3-protobuf_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking python3-protobuf (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package python3-scipy.\n",
            "Preparing to unpack .../43-python3-scipy_0.19.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-scipy (0.19.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-skimage-lib:amd64.\n",
            "Preparing to unpack .../44-python3-skimage-lib_0.13.1-2_amd64.deb ...\n",
            "Unpacking python3-skimage-lib:amd64 (0.13.1-2) ...\n",
            "Selecting previously unselected package python3-pywt.\n",
            "Preparing to unpack .../45-python3-pywt_0.5.1-1.1ubuntu4_amd64.deb ...\n",
            "Unpacking python3-pywt (0.5.1-1.1ubuntu4) ...\n",
            "Selecting previously unselected package python3-skimage.\n",
            "Preparing to unpack .../46-python3-skimage_0.13.1-2_all.deb ...\n",
            "Unpacking python3-skimage (0.13.1-2) ...\n",
            "Selecting previously unselected package python3-caffe-cuda.\n",
            "Preparing to unpack .../47-python3-caffe-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking python3-caffe-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package caffe-cuda.\n",
            "Preparing to unpack .../48-caffe-cuda_1.0.0-6build1_amd64.deb ...\n",
            "Unpacking caffe-cuda (1.0.0-6build1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../49-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libblosc1.\n",
            "Preparing to unpack .../50-libblosc1_1.14.2+ds1-1_amd64.deb ...\n",
            "Unpacking libblosc1 (1.14.2+ds1-1) ...\n",
            "Selecting previously unselected package python-tables-data.\n",
            "Preparing to unpack .../51-python-tables-data_3.4.2-4_all.deb ...\n",
            "Unpacking python-tables-data (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-bs4.\n",
            "Preparing to unpack .../52-python3-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python3-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python3-chardet.\n",
            "Preparing to unpack .../53-python3-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python3-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python3-webencodings.\n",
            "Preparing to unpack .../54-python3-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python3-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python3-html5lib.\n",
            "Preparing to unpack .../55-python3-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python3-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python3-lxml:amd64.\n",
            "Preparing to unpack .../56-python3-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-numexpr.\n",
            "Preparing to unpack .../57-python3-numexpr_2.6.4-1_amd64.deb ...\n",
            "Unpacking python3-numexpr (2.6.4-1) ...\n",
            "Selecting previously unselected package python3-olefile.\n",
            "Preparing to unpack .../58-python3-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python3-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python3-tables-lib.\n",
            "Preparing to unpack .../59-python3-tables-lib_3.4.2-4_amd64.deb ...\n",
            "Unpacking python3-tables-lib (3.4.2-4) ...\n",
            "Selecting previously unselected package python3-tables.\n",
            "Preparing to unpack .../60-python3-tables_3.4.2-4_all.deb ...\n",
            "Unpacking python3-tables (3.4.2-4) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up python3-yaml (3.12-1build2) ...\n",
            "Setting up libblosc1 (1.14.2+ds1-1) ...\n",
            "Setting up python3-pickleshare (0.7.4-2) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Setting up python3-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python3-simplegeneric (0.8.1-1) ...\n",
            "Setting up python3-webencodings (0.5-2) ...\n",
            "Setting up python3-tables-lib (3.4.2-4) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up python3-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python3-olefile (0.45.1-1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-pyparsing (2.2.0+dfsg1-2) ...\n",
            "Setting up python3-cycler (0.10.0-1) ...\n",
            "Setting up python-tables-data (3.4.2-4) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3-bs4 (4.6.0-1) ...\n",
            "Setting up python3-gflags (1.5.1-5) ...\n",
            "update-alternatives: using /usr/bin/python3-gflags2man to provide /usr/bin/gflags2man (gflags2man) in auto mode\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up python3-skimage-lib:amd64 (0.13.1-2) ...\n",
            "Setting up python3-pandas-lib (0.22.0-4ubuntu1) ...\n",
            "Setting up python3-wcwidth (0.1.7+dfsg1-1) ...\n",
            "Setting up libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up python3-protobuf (3.0.0-9.1ubuntu1) ...\n",
            "Setting up python3-ipython-genutils (0.2.0-1) ...\n",
            "Setting up python3-nose (1.3.7-3) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up python3-chardet (3.0.4-1) ...\n",
            "Setting up python3-html5lib (0.999999999-1) ...\n",
            "Setting up libjs-jquery-ui (1.12.1+dfsg-5) ...\n",
            "Setting up libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up ttf-bitstream-vera (1.10-8) ...\n",
            "Setting up cython3 (0.26.1-0.4) ...\n",
            "Setting up python3-pywt (0.5.1-1.1ubuntu4) ...\n",
            "Setting up libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up python3-decorator (4.1.2-1) ...\n",
            "Setting up python3-traitlets (4.3.2-1) ...\n",
            "Setting up python3-ptyprocess (0.5.2-1) ...\n",
            "Setting up python3-tz (2018.3-2) ...\n",
            "Setting up python3-leveldb (0~svn68-3build3) ...\n",
            "Setting up python3-dateutil (2.6.1-1) ...\n",
            "Setting up python3-h5py (2.7.1-2) ...\n",
            "Setting up fonts-lyx (2.2.4-0ubuntu0.18.04.1) ...\n",
            "Setting up python3-pygments (2.2.0+dfsg-1) ...\n",
            "Setting up libcaffe-cuda1:amd64 (1.0.0-6build1) ...\n",
            "Setting up python3-scipy (0.19.1-2ubuntu1) ...\n",
            "Setting up python3-prompt-toolkit (1.0.15-1) ...\n",
            "Setting up python-matplotlib-data (2.1.1-2ubuntu3) ...\n",
            "Setting up python3-numexpr (2.6.4-1) ...\n",
            "Setting up python3-tables (3.4.2-4) ...\n",
            "Setting up python3-pexpect (4.2.1-1) ...\n",
            "Setting up python3-networkx (1.11-1ubuntu3) ...\n",
            "Setting up python3-pandas (0.22.0-4ubuntu1) ...\n",
            "Setting up caffe-tools-cuda (1.0.0-6build1) ...\n",
            "Setting up python3-matplotlib (2.1.1-2ubuntu3) ...\n",
            "Setting up python3-ipython (5.5.0-1) ...\n",
            "Setting up python3-skimage (0.13.1-2) ...\n",
            "Setting up python3-caffe-cuda (1.0.0-6build1) ...\n",
            "Setting up caffe-cuda (1.0.0-6build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6uMEyhSFGTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "c3d0b7b4-e21e-4538-a113-24f31e2b34dc"
      },
      "source": [
        "!git clone --recursive https://github.com/rbgirshick/py-faster-rcnn.git\n",
        "!cd py-faster-rcnn/lib && make\n",
        "!cd py-faster-rcnn/caffe-fast-rcnn && make -j8 && make pycaffe\n",
        "!cd py-faster-rcnn && ./data/scripts/fetch_faster_rcnn_models.sh"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'py-faster-rcnn'...\n",
            "remote: Enumerating objects: 1544, done.\u001b[K\n",
            "remote: Total 1544 (delta 0), reused 0 (delta 0), pack-reused 1544\u001b[K\n",
            "Receiving objects: 100% (1544/1544), 1.36 MiB | 1.27 MiB/s, done.\n",
            "Resolving deltas: 100% (899/899), done.\n",
            "Submodule 'caffe-fast-rcnn' (https://github.com/rbgirshick/caffe-fast-rcnn.git) registered for path 'caffe-fast-rcnn'\n",
            "Cloning into '/content/py-faster-rcnn/caffe-fast-rcnn'...\n",
            "remote: Enumerating objects: 23976, done.        \n",
            "remote: Total 23976 (delta 0), reused 0 (delta 0), pack-reused 23976        \n",
            "Receiving objects: 100% (23976/23976), 31.49 MiB | 9.32 MiB/s, done.\n",
            "Resolving deltas: 100% (15785/15785), done.\n",
            "Submodule path 'caffe-fast-rcnn': checked out '0dcd397b29507b8314e252e850518c5695efbb83'\n",
            "python setup.py build_ext --inplace\n",
            "Traceback (most recent call last):\n",
            "  File \"setup.py\", line 58, in <module>\n",
            "    CUDA = locate_cuda()\n",
            "  File \"setup.py\", line 53, in locate_cuda\n",
            "    for k, v in cudaconfig.iteritems():\n",
            "AttributeError: 'dict' object has no attribute 'iteritems'\n",
            "Makefile:2: recipe for target 'all' failed\n",
            "make: *** [all] Error 1\n",
            "Makefile:6: *** Makefile.config not found. See Makefile.config.example..  Stop.\n",
            "Downloading Faster R-CNN demo models (695M)...\n",
            "--2020-05-18 23:24:19--  https://dl.dropboxusercontent.com/s/o6ii098bu51d139/faster_rcnn_models.tgz?dl=0\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 728560422 (695M) [application/x-gtar]\n",
            "Saving to: faster_rcnn_models.tgz\n",
            "\n",
            "faster_rcnn_models. 100%[===================>] 694.81M  48.8MB/s    in 15s     \n",
            "\n",
            "2020-05-18 23:24:35 (45.7 MB/s) - faster_rcnn_models.tgz saved [728560422/728560422]\n",
            "\n",
            "Unzipping...\n",
            "faster_rcnn_models/\n",
            "faster_rcnn_models/ZF_faster_rcnn_final.caffemodel\n",
            "faster_rcnn_models/VGG16_faster_rcnn_final.caffemodel\n",
            "Done. Please run this command again to verify that checksum = ac116844f66aefe29587214272054668.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9UXNbpgGedH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44312ced-2fe7-4cfc-da32-6296a8db3eb0"
      },
      "source": [
        "!cd py-faster-rcnn/caffe-fast-rcnn && make -j8 && make pycaffe"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CXX .build_release/src/caffe/proto/caffe.pb.cc\n",
            "CXX src/caffe/internal_thread.cpp\n",
            "CXX src/caffe/common.cpp\n",
            "CXX src/caffe/solvers/rmsprop_solver.cpp\n",
            "CXX src/caffe/solvers/nesterov_solver.cpp\n",
            "CXX src/caffe/solvers/adam_solver.cpp\n",
            "CXX src/caffe/solvers/adadelta_solver.cpp\n",
            "CXX src/caffe/solver.cpp\n",
            "In file included from .build_release/src/caffe/proto/caffe.pb.cc:5:0:\n",
            ".build_release/src/caffe/proto/caffe.pb.h:9:10: fatal error: google/protobuf/stubs/common.h: No such file or directory\n",
            " #include <google/protobuf/stubs/common.h>\n",
            "          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "Makefile:570: recipe for target '.build_release/src/caffe/proto/caffe.pb.o' failed\n",
            "make: *** [.build_release/src/caffe/proto/caffe.pb.o] Error 1\n",
            "make: *** Waiting for unfinished jobs....\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/net.hpp:10,\n",
            "                 from ./include/caffe/solver.hpp:7,\n",
            "                 from ./include/caffe/sgd_solvers.hpp:7,\n",
            "                 from src/caffe/solvers/nesterov_solver.cpp:3:\n",
            "./include/caffe/common.hpp:5:10: fatal error: gflags/gflags.h: No such file or directory\n",
            " #include <gflags/gflags.h>\n",
            "          ^~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "Makefile:563: recipe for target '.build_release/src/caffe/solvers/nesterov_solver.o' failed\n",
            "make: *** [.build_release/src/caffe/solvers/nesterov_solver.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/net.hpp:10,\n",
            "                 from ./include/caffe/solver.hpp:7,\n",
            "                 from ./include/caffe/sgd_solvers.hpp:7,\n",
            "                 from src/caffe/solvers/adadelta_solver.cpp:3:\n",
            "./include/caffe/common.hpp:5:10: fatal error: gflags/gflags.h: No such file or directory\n",
            " #include <gflags/gflags.h>\n",
            "          ^~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "Makefile:563: recipe for target '.build_release/src/caffe/solvers/adadelta_solver.o' failed\n",
            "make: *** [.build_release/src/caffe/solvers/adadelta_solver.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/net.hpp:10,\n",
            "                 from ./include/caffe/solver.hpp:7,\n",
            "                 from ./include/caffe/sgd_solvers.hpp:7,\n",
            "                 from src/caffe/solvers/adam_solver.cpp:3:\n",
            "./include/caffe/common.hpp:5:10: fatal error: gflags/gflags.h: No such file or directory\n",
            " #include <gflags/gflags.h>\n",
            "          ^~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "Makefile:563: recipe for target '.build_release/src/caffe/solvers/adam_solver.o' failed\n",
            "make: *** [.build_release/src/caffe/solvers/adam_solver.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/net.hpp:10,\n",
            "                 from ./include/caffe/solver.hpp:7,\n",
            "                 from ./include/caffe/sgd_solvers.hpp:7,\n",
            "                 from src/caffe/solvers/rmsprop_solver.cpp:3:\n",
            "./include/caffe/common.hpp:5:10: fatal error: gflags/gflags.h: No such file or directory\n",
            " #include <gflags/gflags.h>\n",
            "          ^~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "Makefile:563: recipe for target '.build_release/src/caffe/solvers/rmsprop_solver.o' failed\n",
            "make: *** [.build_release/src/caffe/solvers/rmsprop_solver.o] Error 1\n",
            "In file included from ./include/caffe/blob.hpp:8:0,\n",
            "                 from ./include/caffe/net.hpp:10,\n",
            "                 from ./include/caffe/solver.hpp:7,\n",
            "                 from src/caffe/solver.cpp:6:\n",
            "./include/caffe/common.hpp:5:10: fatal error: gflags/gflags.h: No such file or directory\n",
            " #include <gflags/gflags.h>\n",
            "          ^~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "Makefile:563: recipe for target '.build_release/src/caffe/solver.o' failed\n",
            "make: *** [.build_release/src/caffe/solver.o] Error 1\n",
            "In file included from ./include/caffe/internal_thread.hpp:4:0,\n",
            "                 from src/caffe/internal_thread.cpp:4:\n",
            "./include/caffe/common.hpp:5:10: fatal error: gflags/gflags.h: No such file or directory\n",
            " #include <gflags/gflags.h>\n",
            "          ^~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "Makefile:563: recipe for target '.build_release/src/caffe/internal_thread.o' failed\n",
            "make: *** [.build_release/src/caffe/internal_thread.o] Error 1\n",
            "src/caffe/common.cpp:2:10: fatal error: glog/logging.h: No such file or directory\n",
            " #include <glog/logging.h>\n",
            "          ^~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "Makefile:563: recipe for target '.build_release/src/caffe/common.o' failed\n",
            "make: *** [.build_release/src/caffe/common.o] Error 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTPeJCgXHBit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}